{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN with Skorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gramajoguadalupe/RNN_quality_requirement/blob/main/RNN_with_Skorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXYi6BqK2b9",
        "outputId": "61991886-80a2-4d5d-9c8f-788f441f4b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!!uname -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Linux 402eedaa9873 4.19.112+ #1 SMP Thu Jul 23 08:00:38 PDT 2020 x86_64 x86_64 x86_64 GNU/Linux']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0NS05CEK3Tj",
        "outputId": "6b6b7cad-64c8-48ff-815f-5c70889c8bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python 3.6.9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaDdvmm-Bw7V",
        "outputId": "7f3a96ee-f84b-4723-b1c1-54c94fd6bec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!sudo pip install skorch\n",
        "!sudo pip install dstoolbox\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.16.0)\n",
            "Requirement already satisfied: dstoolbox in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (2018.9)\n",
            "Requirement already satisfied: scikit-learn<0.24dev0,>=0.21 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from dstoolbox) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.24dev0,>=0.21->dstoolbox) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeL3o-QjIGM9",
        "outputId": "fcb32ac2-a531-4876-8899-d06d48560482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CeSWV39Idfn"
      },
      "source": [
        "import os\n",
        "import tarfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6kOa3KwIaie"
      },
      "source": [
        "from dstoolbox.transformers import Padder2d\n",
        "from dstoolbox.transformers import TextFeaturizer\n",
        "from scipy import stats\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from skorch import NeuralNetClassifier\n",
        "F = nn.functional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2TNu6IIkSM"
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fmJwPV3Q9SO",
        "outputId": "cc5813e5-a87c-434b-9bba-12653acdd21b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f2df460-0cda-4047-b1a5-ebbdba641b40\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f2df460-0cda-4047-b1a5-ebbdba641b40\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 27-08-2020CorpusRE.xlsx to 27-08-2020CorpusRE.xlsx\n",
            "User uploaded file \"27-08-2020CorpusRE.xlsx\" with length 147767 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1c4JcEhw3pf"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Re2Xngq09Mn"
      },
      "source": [
        "def pad_features(req_tagged, longitud):\n",
        "    ''' Devuelve las oraciones taggeadas, donde son agregados zeros a la \n",
        "    izquierda para equiparar la longitud estipulada por el parametro longitud.\n",
        "    Si el requirimiento ya posee el tamaño de lo estipulado esta toma los \n",
        "    longitud primeras palabras\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(req_tagged), longitud), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(req_tagged):\n",
        "        features[i, -len(row):] = np.array(row)[:longitud]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKd01jiDQ0rP"
      },
      "source": [
        "df = pd.read_excel('27-08-2020CorpusRE.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXgGtG7bS1a9",
        "outputId": "3954ac08-2e12-4f0b-9080-99ea4369610d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Requirements</th>\n",
              "      <th>Completo</th>\n",
              "      <th>No Completo</th>\n",
              "      <th>Tokenized</th>\n",
              "      <th>Pos_tagged</th>\n",
              "      <th>Tagged_Req</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The system shall have a MDI form that allows f...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['The', 'system', 'shall', 'have', 'a', 'MDI',...</td>\n",
              "      <td>[('The', 'DT'), ('system', 'NN'), ('shall', 'M...</td>\n",
              "      <td>DT,NN,MD,VB,DT,NNP,NN,WDT,VBZ,IN,DT,NN,IN,DT,N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The system shall display Events in a vertical ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['The', 'system', 'shall', 'display', 'Events'...</td>\n",
              "      <td>[('The', 'DT'), ('system', 'NN'), ('shall', 'M...</td>\n",
              "      <td>DT,NN,MD,VB,NNS,IN,DT,JJ,NN,IN,NN,.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The system shall display the Events in a graph...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['The', 'system', 'shall', 'display', 'the', '...</td>\n",
              "      <td>[('The', 'DT'), ('system', 'NN'), ('shall', 'M...</td>\n",
              "      <td>DT,NN,MD,VB,DT,NNS,IN,DT,NN,IN,NN,.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The Disputes System must be accessible by both...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['The', 'Disputes', 'System', 'must', 'be', 'a...</td>\n",
              "      <td>[('The', 'DT'), ('Disputes', 'NNP'), ('System'...</td>\n",
              "      <td>DT,NNP,NNP,MD,VB,JJ,IN,DT,JJ,CC,JJ,NNS,.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The Disputes System must prevent users from ac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['The', 'Disputes', 'System', 'must', 'prevent...</td>\n",
              "      <td>[('The', 'DT'), ('Disputes', 'NNP'), ('System'...</td>\n",
              "      <td>DT,NNP,NNP,MD,VB,NNS,IN,VBG,DT,NN,NNS,WDT,VBP,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         Tagged_Req\n",
              "0           0  ...  DT,NN,MD,VB,DT,NNP,NN,WDT,VBZ,IN,DT,NN,IN,DT,N...\n",
              "1           1  ...                DT,NN,MD,VB,NNS,IN,DT,JJ,NN,IN,NN,.\n",
              "2           2  ...                DT,NN,MD,VB,DT,NNS,IN,DT,NN,IN,NN,.\n",
              "3           3  ...           DT,NNP,NNP,MD,VB,JJ,IN,DT,JJ,CC,JJ,NNS,.\n",
              "4           4  ...  DT,NNP,NNP,MD,VB,NNS,IN,VBG,DT,NN,NNS,WDT,VBP,...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTSzk5kZj3g2",
        "outputId": "6a08da2c-e91c-44c3-e704-0d34cd30244f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAK10Qa8Ip5j"
      },
      "source": [
        "VOCAB_SIZE = 38  # This is on the low end\n",
        "MAX_LEN = 100  # Texts are pretty long on average, this is on the low end\n",
        "USE_CUDA = train_on_gpu  # Set this to False if you don't want to use CUDA\n",
        "NUM_CV_STEPS = 10  # Number of randomized search steps to perform (cross validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRVP3rXNJV76"
      },
      "source": [
        "dataset = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqg8eMw5I3mB"
      },
      "source": [
        "X, y = dataset['Tagged_Req'], dataset['Completo']\n",
        "#X = np.asarray([x for x in X])  # decode from bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtt9l_2hS-Wm",
        "outputId": "43a2211b-cac9-4993-e51d-a6b9e80a575e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for text, target in zip(X[:3], y):    \n",
        "    print(\"Target: {}\".format(target))\n",
        "    print(f\"POS tagged Requirement {text}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0\n",
            "POS tagged Requirement DT,NN,MD,VB,DT,NNP,NN,WDT,VBZ,IN,DT,NN,IN,DT,NN,CC,DT,NNS,NN,.\n",
            "\n",
            "Target: 1\n",
            "POS tagged Requirement DT,NN,MD,VB,NNS,IN,DT,JJ,NN,IN,NN,.\n",
            "\n",
            "Target: 1\n",
            "POS tagged Requirement DT,NN,MD,VB,DT,NNS,IN,DT,NN,IN,NN,.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oHk_8ChJZ6p"
      },
      "source": [
        "steps = [\n",
        "    ('to_idx', TextFeaturizer(max_features = VOCAB_SIZE)),\n",
        "    ('pad', Padder2d(max_len = MAX_LEN, pad_value = 0, dtype = int)),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OQe8NAu2tdQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMRp_daYUJij",
        "outputId": "6cb8cb9f-81c9-4a12-db99-513b2f696296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "Pipeline(steps).fit_transform(X[:])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 10,  9, ...,  0,  0,  0],\n",
              "       [ 2, 10,  9, ...,  0,  0,  0],\n",
              "       [ 2, 10,  9, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 2, 11, 11, ...,  0,  0,  0],\n",
              "       [30,  2, 10, ...,  0,  0,  0],\n",
              "       [30, 10, 27, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw-b-OfgxqPB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRI-14wcUsnn"
      },
      "source": [
        "class RequirementRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Requirement analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rec_layer_type='lstm', embedding_dim=128, num_units=128, num_layers=2, dropout=0.3):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.rec_layer_type = rec_layer_type.lower()\n",
        "        self.num_units = num_units\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout   \n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.emb = nn.Embedding(VOCAB_SIZE + 1, embedding_dim=self.embedding_dim)\n",
        "        rec_layer = {'lstm': nn.LSTM, 'gru': nn.GRU}[self.rec_layer_type]\n",
        "             \n",
        "        # linear and sigmoid layers\n",
        "        self.rec = rec_layer(\n",
        "            self.embedding_dim, self.num_units, num_layers=num_layers, batch_first=True)\n",
        "      \n",
        "\n",
        "        self.output = nn.Linear(self.num_units, 2)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        de que manera se recorre la red neuronal\n",
        "        ivar: X es el req de entrada        \n",
        "        \"\"\"\n",
        "        embeddings = self.emb(X)\n",
        "        # from the recurrent layer, only take the activities from the last sequence step\n",
        "        if self.rec_layer_type == 'gru':\n",
        "            _, rec_out = self.rec(embeddings)\n",
        "        else:\n",
        "            _, (rec_out, _) = self.rec(embeddings)\n",
        "        rec_out = rec_out[-1]  # take output of last RNN layer transforma la matriz en un vector o reducción dimensional \n",
        "        drop = F.dropout(rec_out, p=self.dropout)\n",
        "        # Remember that the final non-linearity should be softmax, so that our predict_proba\n",
        "        # method outputs actual probabilities!\n",
        "        preout = self.output(drop)\n",
        "        out = F.softmax(preout, dim=-1)\n",
        "        return out    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1wnoUyS6Kt1"
      },
      "source": [
        "X_transformado = Pipeline(steps).fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uaj4xqG0xuyk",
        "outputId": "860dfb2f-a6d2-411a-a898-b6ec80c0eb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_transformado[323]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 10, 27, 25, 10, 27, 25,  5, 10,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cntSAxtyBrU",
        "outputId": "11deb22e-7640-42da-f4e9-a24d8e0c39c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_transformado[322]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 27, 25, 30, 18, 26, 25, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVWXvyRFd4Z0"
      },
      "source": [
        "steps.append(\n",
        "    ('net', NeuralNetClassifier(\n",
        "        RequirementRNN,\n",
        "        device=('cuda' if USE_CUDA else 'cpu'),\n",
        "        max_epochs=30,\n",
        "        lr=0.01,\n",
        "        optimizer=torch.optim.Adam,\n",
        "    ))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQpauaI5y9y"
      },
      "source": [
        "modelo_neuronal =  NeuralNetClassifier(\n",
        "        RequirementRNN,\n",
        "        device=('cuda' if USE_CUDA else 'cpu'),\n",
        "        max_epochs=30,\n",
        "        lr=0.01,\n",
        "        optimizer=torch.optim.Adam\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF3ltcyo_3FW"
      },
      "source": [
        "  epoch    train_loss    valid_acc    valid_loss     dur\n",
        "-------  ------------  -----------  ------------  ------\n",
        "      1        2.0338       0.5000        0.7431  0.5301\n",
        "      2        0.7711       0.5000        0.7144  0.5356\n",
        "      3        0.6884       0.5000        0.6969  0.5252\n",
        "      4        0.6870       0.5625        0.6903  0.5286\n",
        "      5        0.6898       0.5156        0.6950  0.5643\n",
        "      6        0.6920       0.5156        0.6932  0.5599\n",
        "      7        0.6937       0.5312        0.6927  0.5363\n",
        "      8        0.6950       0.5312        0.6904  0.5183\n",
        "      9        0.6941       0.5312        0.6907  0.5277\n",
        "     10        0.6897       0.5312        0.6849  0.5340\n",
        "     11        0.6869       0.5312        0.6803  0.5470\n",
        "     12        0.6839       0.5312        0.6745  0.5479\n",
        "     13        0.6709       0.5625        0.6691  0.5327\n",
        "     14        0.6656       0.6094        0.6543  0.5195\n",
        "     15        0.6645       0.6094        0.6500  0.5470\n",
        "     16        0.6602       0.6094        0.6510  0.5233\n",
        "     17        0.6622       0.5938        0.6543  0.5564\n",
        "     18        0.6589       0.6250        0.6484  0.5356\n",
        "     19        0.6576       0.6250        0.6455  0.5651\n",
        "     20        0.6576       0.6094        0.6448  0.5130\n",
        "     21        0.6555       0.6562        0.6410  0.5393\n",
        "     22        0.6539       0.7188        0.6339  0.5197\n",
        "     23        0.6506       0.7344        0.6245  0.5202\n",
        "     24        0.6480       0.7344        0.6178  0.5704\n",
        "     25        0.6398       0.7500        0.6163  0.5357\n",
        "     26        0.6394       0.7656        0.6086  0.5140\n",
        "     27        0.6322       0.7344        0.5885  0.5476\n",
        "     28        0.6190       0.7656        0.5755  0.5371\n",
        "     29        0.6027       0.7500        0.5544  0.5263\n",
        "     30        0.5856       0.7656        0.5429  0.5197\n",
        "CPU times: user 15.9 s, sys: 202 ms, total: 16.1 s\n",
        "Wall time: 16.3 s\n",
        "Pipeline(memory=None,\n",
        "         steps=[('to_idx',\n",
        "                 TextFeaturizer(analyzer='word', binary=False,\n",
        "                                decode_error='strict',\n",
        "                                dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
        "                                input='content', lowercase=True, max_df=1.0,\n",
        "                                max_features=38, min_df=1, ngram_range=(1, 1),\n",
        "                                preprocessor=None, stop_words=None,\n",
        "                                strip_accents=None,\n",
        "                                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "                                tokenizer=None, unknown_token=None,\n",
        "                                vocabulary=None)),\n",
        "                ('pad',\n",
        "                 Padder2d(dtype=<class 'int'>, max_len=38, pad_value=38)),\n",
        "                ('net',\n",
        "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
        "  module_=RequirementRNN(\n",
        "    (emb): Embedding(39, 128)\n",
        "    (rec): LSTM(128, 128, num_layers=2, batch_first=True)\n",
        "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
        "  ),\n",
        "))],\n",
        "         verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BF8icFe7Eg",
        "outputId": "54ead82a-0a77-4e75-8596-e3af40e1d71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "#pipe.set_params(net__verbose=0, net__train_split=None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-200-2a1cd9cc6bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet__verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet__train_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuDed61V8LL2"
      },
      "source": [
        "params = {    \n",
        "    'module__embedding_dim': [64,128,256],#stats.randint(32, 256 + 1),\n",
        "    'module__rec_layer_type': ['gru', 'lstm'],\n",
        "    'module__num_units': [64,128,256],#stats.randint(32, 256 + 1),\n",
        "    'module__num_layers': [1,2],\n",
        "    'module__dropout': [0,0.1,0.3],#stats.uniform(0, 0.9),\n",
        "    'lr': [0.1,0.01,0.001],#[10**(-stats.uniform(1, 5).rvs()) for _ in range(NUM_CV_STEPS)],\n",
        "    'max_epochs': [3,4,5, 10,30,40],    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozWVRkd57Q7r"
      },
      "source": [
        "search = RandomizedSearchCV(\n",
        "    modelo_neuronal, params, n_iter=NUM_CV_STEPS, verbose=0, refit=True, scoring='accuracy', cv=10) # se puede agregar otras metricas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h7gwxW_7V8L",
        "outputId": "8605be85-d937-41f4-aec2-5002684ab7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%time search.fit(X_transformado, y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7273\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5679\u001b[0m  0.0603\n",
            "      2        \u001b[36m0.5657\u001b[0m       0.7557        0.5683  0.0548\n",
            "      3        0.5665       0.7557        \u001b[35m0.5566\u001b[0m  0.0552\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7016\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5689\u001b[0m  0.0512\n",
            "      2        \u001b[36m0.5675\u001b[0m       0.7500        \u001b[35m0.5680\u001b[0m  0.0528\n",
            "      3        \u001b[36m0.5645\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0534\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7397\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5768\u001b[0m  0.0555\n",
            "      2        \u001b[36m0.5693\u001b[0m       0.7500        \u001b[35m0.5739\u001b[0m  0.0532\n",
            "      3        \u001b[36m0.5660\u001b[0m       0.7500        \u001b[35m0.5598\u001b[0m  0.0534\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7068\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5642\u001b[0m  0.0512\n",
            "      2        \u001b[36m0.5613\u001b[0m       0.7500        0.5659  0.0528\n",
            "      3        \u001b[36m0.5524\u001b[0m       0.7500        \u001b[35m0.5576\u001b[0m  0.0529\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8063\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5724\u001b[0m  0.0508\n",
            "      2        \u001b[36m0.5707\u001b[0m       0.7500        \u001b[35m0.5608\u001b[0m  0.0517\n",
            "      3        0.5768       0.7500        0.5609  0.0522\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7963\u001b[0m       \u001b[32m0.7443\u001b[0m        \u001b[35m0.5876\u001b[0m  0.0513\n",
            "      2        \u001b[36m0.5908\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5626\u001b[0m  0.0532\n",
            "      3        \u001b[36m0.5697\u001b[0m       0.7500        0.5710  0.0524\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7902\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5919\u001b[0m  0.0510\n",
            "      2        \u001b[36m0.5943\u001b[0m       0.7500        \u001b[35m0.5657\u001b[0m  0.0526\n",
            "      3        \u001b[36m0.5652\u001b[0m       0.7500        0.5700  0.0524\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7707\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5932\u001b[0m  0.0519\n",
            "      2        \u001b[36m0.5792\u001b[0m       0.7500        \u001b[35m0.5686\u001b[0m  0.0546\n",
            "      3        0.5792       0.7500        \u001b[35m0.5675\u001b[0m  0.0533\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8065\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5726\u001b[0m  0.0553\n",
            "      2        \u001b[36m0.5808\u001b[0m       0.7500        \u001b[35m0.5585\u001b[0m  0.0543\n",
            "      3        \u001b[36m0.5753\u001b[0m       0.7500        0.5625  0.0536\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8127\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0509\n",
            "      2        \u001b[36m0.5913\u001b[0m       0.7500        \u001b[35m0.5696\u001b[0m  0.0535\n",
            "      3        \u001b[36m0.5846\u001b[0m       0.7500        \u001b[35m0.5679\u001b[0m  0.0524\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4282\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5856\u001b[0m  0.0707\n",
            "      2        \u001b[36m0.5856\u001b[0m       0.7557        \u001b[35m0.5849\u001b[0m  0.0722\n",
            "      3        \u001b[36m0.5789\u001b[0m       0.7557        \u001b[35m0.5612\u001b[0m  0.0711\n",
            "      4        \u001b[36m0.5607\u001b[0m       0.7557        \u001b[35m0.5570\u001b[0m  0.0739\n",
            "      5        \u001b[36m0.5547\u001b[0m       0.7557        0.5587  0.0764\n",
            "      6        0.5586       0.7557        \u001b[35m0.5561\u001b[0m  0.0729\n",
            "      7        0.5569       0.7557        0.5566  0.0716\n",
            "      8        0.5552       0.7557        0.5563  0.0718\n",
            "      9        0.5569       0.7557        \u001b[35m0.5560\u001b[0m  0.0734\n",
            "     10        0.5566       0.7557        0.5561  0.0746\n",
            "     11        0.5560       0.7557        0.5560  0.0721\n",
            "     12        0.5568       0.7557        \u001b[35m0.5560\u001b[0m  0.0738\n",
            "     13        0.5567       0.7557        0.5560  0.0738\n",
            "     14        0.5566       0.7557        0.5560  0.0723\n",
            "     15        0.5569       0.7557        0.5560  0.0725\n",
            "     16        0.5569       0.7557        0.5560  0.0729\n",
            "     17        0.5569       0.7557        \u001b[35m0.5560\u001b[0m  0.0720\n",
            "     18        0.5571       0.7557        0.5560  0.0720\n",
            "     19        0.5571       0.7557        0.5560  0.0719\n",
            "     20        0.5571       0.7557        0.5560  0.0722\n",
            "     21        0.5572       0.7557        0.5560  0.0728\n",
            "     22        0.5572       0.7557        0.5560  0.0718\n",
            "     23        0.5573       0.7557        0.5560  0.0759\n",
            "     24        0.5573       0.7557        0.5560  0.0781\n",
            "     25        0.5573       0.7557        0.5560  0.0732\n",
            "     26        0.5574       0.7557        0.5560  0.0728\n",
            "     27        0.5574       0.7557        0.5560  0.0718\n",
            "     28        0.5574       0.7557        0.5560  0.0716\n",
            "     29        0.5575       0.7557        0.5560  0.0741\n",
            "     30        0.5575       0.7557        0.5560  0.0715\n",
            "     31        0.5575       0.7557        0.5560  0.0712\n",
            "     32        0.5575       0.7557        0.5560  0.0714\n",
            "     33        0.5575       0.7557        0.5560  0.0717\n",
            "     34        0.5576       0.7557        0.5560  0.0715\n",
            "     35        0.5576       0.7557        0.5560  0.0712\n",
            "     36        0.5576       0.7557        0.5560  0.0729\n",
            "     37        0.5576       0.7557        0.5560  0.0714\n",
            "     38        0.5576       0.7557        0.5560  0.0746\n",
            "     39        0.5577       0.7557        0.5560  0.0717\n",
            "     40        0.5577       0.7557        0.5560  0.0723\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2544\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6118\u001b[0m  0.0700\n",
            "      2        \u001b[36m0.5667\u001b[0m       0.7500        \u001b[35m0.5992\u001b[0m  0.0727\n",
            "      3        0.5812       0.7500        \u001b[35m0.5636\u001b[0m  0.0724\n",
            "      4        \u001b[36m0.5648\u001b[0m       0.7500        \u001b[35m0.5636\u001b[0m  0.0705\n",
            "      5        \u001b[36m0.5561\u001b[0m       0.7500        0.5680  0.0723\n",
            "      6        0.5617       0.7500        \u001b[35m0.5630\u001b[0m  0.0759\n",
            "      7        0.5578       0.7500        \u001b[35m0.5624\u001b[0m  0.0724\n",
            "      8        0.5575       0.7500        0.5632  0.0737\n",
            "      9        0.5590       0.7500        0.5625  0.0714\n",
            "     10        0.5571       0.7500        0.5627  0.0796\n",
            "     11        0.5584       0.7500        0.5624  0.0723\n",
            "     12        0.5583       0.7500        \u001b[35m0.5623\u001b[0m  0.0717\n",
            "     13        0.5579       0.7500        0.5625  0.0707\n",
            "     14        0.5586       0.7500        0.5624  0.0725\n",
            "     15        0.5582       0.7500        0.5624  0.0709\n",
            "     16        0.5584       0.7500        0.5624  0.0718\n",
            "     17        0.5586       0.7500        0.5624  0.0715\n",
            "     18        0.5585       0.7500        0.5624  0.0709\n",
            "     19        0.5587       0.7500        0.5624  0.0733\n",
            "     20        0.5586       0.7500        0.5624  0.0819\n",
            "     21        0.5587       0.7500        0.5624  0.0712\n",
            "     22        0.5588       0.7500        0.5624  0.0713\n",
            "     23        0.5588       0.7500        0.5624  0.0765\n",
            "     24        0.5589       0.7500        0.5624  0.0824\n",
            "     25        0.5589       0.7500        0.5624  0.0714\n",
            "     26        0.5589       0.7500        0.5624  0.0725\n",
            "     27        0.5589       0.7500        0.5624  0.0715\n",
            "     28        0.5590       0.7500        0.5624  0.0723\n",
            "     29        0.5590       0.7500        0.5624  0.0732\n",
            "     30        0.5590       0.7500        0.5624  0.0714\n",
            "     31        0.5590       0.7500        0.5624  0.0710\n",
            "     32        0.5591       0.7500        0.5624  0.0715\n",
            "     33        0.5591       0.7500        0.5624  0.0718\n",
            "     34        0.5591       0.7500        0.5624  0.0719\n",
            "     35        0.5591       0.7500        0.5624  0.0711\n",
            "     36        0.5591       0.7500        0.5624  0.0726\n",
            "     37        0.5591       0.7500        0.5624  0.0788\n",
            "     38        0.5592       0.7500        0.5624  0.0720\n",
            "     39        0.5592       0.7500        0.5624  0.0722\n",
            "     40        0.5592       0.7500        0.5624  0.0722\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5184\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5724\u001b[0m  0.0702\n",
            "      2        \u001b[36m0.6128\u001b[0m       0.7500        0.5901  0.0723\n",
            "      3        \u001b[36m0.5797\u001b[0m       0.7500        0.5796  0.0714\n",
            "      4        \u001b[36m0.5578\u001b[0m       0.7500        0.5743  0.0726\n",
            "      5        0.5689       0.7500        \u001b[35m0.5632\u001b[0m  0.0739\n",
            "      6        0.5609       0.7500        \u001b[35m0.5624\u001b[0m  0.0720\n",
            "      7        0.5598       0.7500        0.5634  0.0725\n",
            "      8        0.5606       0.7500        0.5627  0.0783\n",
            "      9        \u001b[36m0.5576\u001b[0m       0.7500        0.5632  0.0785\n",
            "     10        0.5603       0.7500        \u001b[35m0.5623\u001b[0m  0.0760\n",
            "     11        0.5590       0.7500        0.5625  0.0744\n",
            "     12        0.5596       0.7500        0.5625  0.0716\n",
            "     13        0.5600       0.7500        0.5624  0.0712\n",
            "     14        0.5596       0.7500        0.5625  0.0720\n",
            "     15        0.5603       0.7500        0.5624  0.0719\n",
            "     16        0.5600       0.7500        0.5625  0.0716\n",
            "     17        0.5604       0.7500        0.5624  0.0720\n",
            "     18        0.5603       0.7500        0.5624  0.0727\n",
            "     19        0.5605       0.7500        0.5624  0.0731\n",
            "     20        0.5606       0.7500        0.5624  0.0717\n",
            "     21        0.5607       0.7500        0.5624  0.0749\n",
            "     22        0.5608       0.7500        0.5624  0.0764\n",
            "     23        0.5608       0.7500        0.5624  0.0774\n",
            "     24        0.5609       0.7500        0.5624  0.0719\n",
            "     25        0.5610       0.7500        0.5624  0.0721\n",
            "     26        0.5611       0.7500        0.5624  0.0732\n",
            "     27        0.5611       0.7500        0.5624  0.0716\n",
            "     28        0.5612       0.7500        0.5624  0.0718\n",
            "     29        0.5612       0.7500        0.5624  0.0738\n",
            "     30        0.5613       0.7500        0.5624  0.0734\n",
            "     31        0.5613       0.7500        0.5624  0.0714\n",
            "     32        0.5614       0.7500        0.5624  0.0711\n",
            "     33        0.5614       0.7500        0.5624  0.0715\n",
            "     34        0.5614       0.7500        0.5624  0.0713\n",
            "     35        0.5615       0.7500        0.5624  0.0711\n",
            "     36        0.5615       0.7500        0.5624  0.0720\n",
            "     37        0.5616       0.7500        0.5624  0.0750\n",
            "     38        0.5616       0.7500        0.5624  0.0778\n",
            "     39        0.5616       0.7500        0.5624  0.0815\n",
            "     40        0.5616       0.7500        0.5625  0.0709\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3396\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5774\u001b[0m  0.0701\n",
            "      2        \u001b[36m0.5731\u001b[0m       0.7500        0.6035  0.0712\n",
            "      3        0.5876       0.7500        0.5782  0.0715\n",
            "      4        \u001b[36m0.5532\u001b[0m       0.7500        0.5789  0.0739\n",
            "      5        0.5674       0.7500        \u001b[35m0.5637\u001b[0m  0.0711\n",
            "      6        0.5578       0.7500        0.5648  0.0718\n",
            "      7        0.5583       0.7500        \u001b[35m0.5628\u001b[0m  0.0714\n",
            "      8        0.5592       0.7500        \u001b[35m0.5627\u001b[0m  0.0715\n",
            "      9        0.5560       0.7500        0.5636  0.0723\n",
            "     10        0.5591       0.7500        \u001b[35m0.5626\u001b[0m  0.0766\n",
            "     11        0.5564       0.7500        0.5636  0.0725\n",
            "     12        0.5588       0.7500        0.5628  0.0714\n",
            "     13        0.5572       0.7500        0.5634  0.0733\n",
            "     14        0.5587       0.7500        0.5630  0.0721\n",
            "     15        0.5579       0.7500        0.5633  0.0712\n",
            "     16        0.5587       0.7500        0.5631  0.0717\n",
            "     17        0.5583       0.7500        0.5633  0.0711\n",
            "     18        0.5588       0.7500        0.5633  0.0748\n",
            "     19        0.5587       0.7500        0.5633  0.0746\n",
            "     20        0.5589       0.7500        0.5633  0.0727\n",
            "     21        0.5590       0.7500        0.5633  0.0716\n",
            "     22        0.5591       0.7500        0.5634  0.0712\n",
            "     23        0.5592       0.7500        0.5634  0.0740\n",
            "     24        0.5592       0.7500        0.5634  0.0754\n",
            "     25        0.5594       0.7500        0.5634  0.0716\n",
            "     26        0.5594       0.7500        0.5634  0.0723\n",
            "     27        0.5595       0.7500        0.5634  0.0741\n",
            "     28        0.5595       0.7500        0.5635  0.0717\n",
            "     29        0.5596       0.7500        0.5635  0.0721\n",
            "     30        0.5597       0.7500        0.5635  0.0717\n",
            "     31        0.5597       0.7500        0.5635  0.0725\n",
            "     32        0.5598       0.7500        0.5635  0.0723\n",
            "     33        0.5598       0.7500        0.5635  0.0722\n",
            "     34        0.5599       0.7500        0.5635  0.0724\n",
            "     35        0.5599       0.7500        0.5635  0.0717\n",
            "     36        0.5600       0.7500        0.5636  0.0742\n",
            "     37        0.5600       0.7500        0.5636  0.0762\n",
            "     38        0.5600       0.7500        0.5636  0.0718\n",
            "     39        0.5601       0.7500        0.5636  0.0818\n",
            "     40        0.5601       0.7500        0.5636  0.0834\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.9034\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5917\u001b[0m  0.0742\n",
            "      2        \u001b[36m0.6607\u001b[0m       0.7500        0.6186  0.0717\n",
            "      3        \u001b[36m0.6016\u001b[0m       0.7500        0.6066  0.0716\n",
            "      4        \u001b[36m0.5716\u001b[0m       0.7500        \u001b[35m0.5813\u001b[0m  0.0719\n",
            "      5        0.5842       0.7500        \u001b[35m0.5641\u001b[0m  0.0778\n",
            "      6        \u001b[36m0.5664\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0711\n",
            "      7        \u001b[36m0.5661\u001b[0m       0.7500        0.5644  0.0727\n",
            "      8        0.5671       0.7500        0.5642  0.0727\n",
            "      9        \u001b[36m0.5637\u001b[0m       0.7500        0.5628  0.0720\n",
            "     10        0.5670       0.7500        \u001b[35m0.5624\u001b[0m  0.0767\n",
            "     11        0.5653       0.7500        \u001b[35m0.5624\u001b[0m  0.0718\n",
            "     12        0.5659       0.7500        \u001b[35m0.5624\u001b[0m  0.0718\n",
            "     13        0.5664       0.7500        0.5625  0.0713\n",
            "     14        0.5659       0.7500        \u001b[35m0.5623\u001b[0m  0.0714\n",
            "     15        0.5668       0.7500        0.5624  0.0717\n",
            "     16        0.5665       0.7500        \u001b[35m0.5623\u001b[0m  0.0715\n",
            "     17        0.5669       0.7500        \u001b[35m0.5623\u001b[0m  0.0716\n",
            "     18        0.5670       0.7500        0.5624  0.0712\n",
            "     19        0.5670       0.7500        \u001b[35m0.5623\u001b[0m  0.0719\n",
            "     20        0.5673       0.7500        0.5624  0.0723\n",
            "     21        0.5673       0.7500        0.5623  0.0712\n",
            "     22        0.5675       0.7500        0.5623  0.0714\n",
            "     23        0.5675       0.7500        0.5623  0.0716\n",
            "     24        0.5676       0.7500        0.5623  0.0758\n",
            "     25        0.5677       0.7500        0.5623  0.0767\n",
            "     26        0.5677       0.7500        0.5623  0.0756\n",
            "     27        0.5678       0.7500        0.5623  0.0713\n",
            "     28        0.5679       0.7500        0.5623  0.0721\n",
            "     29        0.5679       0.7500        0.5623  0.0715\n",
            "     30        0.5680       0.7500        0.5623  0.0722\n",
            "     31        0.5681       0.7500        0.5623  0.0718\n",
            "     32        0.5681       0.7500        0.5623  0.0719\n",
            "     33        0.5682       0.7500        0.5623  0.0719\n",
            "     34        0.5682       0.7500        0.5623  0.0716\n",
            "     35        0.5682       0.7500        0.5623  0.0741\n",
            "     36        0.5683       0.7500        0.5623  0.0801\n",
            "     37        0.5683       0.7500        0.5623  0.0818\n",
            "     38        0.5684       0.7500        0.5623  0.0791\n",
            "     39        0.5684       0.7500        0.5623  0.0722\n",
            "     40        0.5684       0.7500        0.5623  0.0717\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5309\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5628\u001b[0m  0.0709\n",
            "      2        \u001b[36m0.8390\u001b[0m       0.7500        0.5748  0.0743\n",
            "      3        \u001b[36m0.6246\u001b[0m       0.7500        0.5640  0.0716\n",
            "      4        0.6955       0.7500        \u001b[35m0.5624\u001b[0m  0.0718\n",
            "      5        \u001b[36m0.5917\u001b[0m       0.7500        0.5631  0.0729\n",
            "      6        0.6456       0.7500        0.5686  0.0769\n",
            "      7        \u001b[36m0.5800\u001b[0m       0.7500        0.5640  0.0717\n",
            "      8        0.6213       0.7500        0.5796  0.0751\n",
            "      9        0.5817       0.7500        0.5629  0.0780\n",
            "     10        0.6046       0.7500        0.5769  0.0764\n",
            "     11        0.5906       0.7500        0.5627  0.0783\n",
            "     12        0.5950       0.7500        0.5685  0.0816\n",
            "     13        0.5980       0.7500        0.5661  0.0717\n",
            "     14        0.5932       0.7500        0.5651  0.0719\n",
            "     15        0.5999       0.7500        0.5682  0.0739\n",
            "     16        0.5962       0.7500        0.5653  0.0715\n",
            "     17        0.5990       0.7500        0.5673  0.0709\n",
            "     18        0.5994       0.7500        0.5666  0.0716\n",
            "     19        0.5989       0.7500        0.5665  0.0719\n",
            "     20        0.6008       0.7500        0.5672  0.0716\n",
            "     21        0.6002       0.7500        0.5666  0.0719\n",
            "     22        0.6011       0.7500        0.5671  0.0734\n",
            "     23        0.6015       0.7500        0.5670  0.0733\n",
            "     24        0.6016       0.7500        0.5670  0.0756\n",
            "     25        0.6023       0.7500        0.5672  0.0759\n",
            "     26        0.6024       0.7500        0.5671  0.0720\n",
            "     27        0.6027       0.7500        0.5672  0.0722\n",
            "     28        0.6030       0.7500        0.5672  0.0802\n",
            "     29        0.6032       0.7500        0.5672  0.0722\n",
            "     30        0.6035       0.7500        0.5673  0.0717\n",
            "     31        0.6037       0.7500        0.5673  0.0736\n",
            "     32        0.6038       0.7500        0.5673  0.0717\n",
            "     33        0.6041       0.7500        0.5674  0.0719\n",
            "     34        0.6042       0.7500        0.5674  0.0744\n",
            "     35        0.6044       0.7500        0.5674  0.0808\n",
            "     36        0.6045       0.7500        0.5674  0.0773\n",
            "     37        0.6047       0.7500        0.5674  0.0767\n",
            "     38        0.6048       0.7500        0.5674  0.0740\n",
            "     39        0.6049       0.7500        0.5675  0.0732\n",
            "     40        0.6051       0.7500        0.5675  0.0724\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5977\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5723\u001b[0m  0.0704\n",
            "      2        \u001b[36m0.6719\u001b[0m       0.7500        0.5933  0.0714\n",
            "      3        \u001b[36m0.5641\u001b[0m       0.7500        0.5798  0.0720\n",
            "      4        0.5672       0.7500        \u001b[35m0.5627\u001b[0m  0.0738\n",
            "      5        \u001b[36m0.5635\u001b[0m       0.7500        0.5673  0.0720\n",
            "      6        \u001b[36m0.5593\u001b[0m       0.7500        0.5628  0.0716\n",
            "      7        \u001b[36m0.5568\u001b[0m       0.7500        0.5641  0.0716\n",
            "      8        0.5586       0.7500        \u001b[35m0.5626\u001b[0m  0.0801\n",
            "      9        0.5588       0.7500        \u001b[35m0.5623\u001b[0m  0.0719\n",
            "     10        0.5571       0.7500        0.5630  0.0762\n",
            "     11        0.5581       0.7500        0.5624  0.0739\n",
            "     12        0.5586       0.7500        0.5624  0.0714\n",
            "     13        0.5580       0.7500        0.5626  0.0721\n",
            "     14        0.5584       0.7500        0.5624  0.0716\n",
            "     15        0.5587       0.7500        0.5624  0.0713\n",
            "     16        0.5585       0.7500        0.5625  0.0716\n",
            "     17        0.5587       0.7500        0.5625  0.0732\n",
            "     18        0.5589       0.7500        0.5624  0.0713\n",
            "     19        0.5589       0.7500        0.5625  0.0714\n",
            "     20        0.5590       0.7500        0.5625  0.0726\n",
            "     21        0.5591       0.7500        0.5625  0.0748\n",
            "     22        0.5591       0.7500        0.5625  0.0714\n",
            "     23        0.5592       0.7500        0.5625  0.0752\n",
            "     24        0.5593       0.7500        0.5625  0.0815\n",
            "     25        0.5593       0.7500        0.5625  0.0714\n",
            "     26        0.5594       0.7500        0.5625  0.0718\n",
            "     27        0.5594       0.7500        0.5625  0.0726\n",
            "     28        0.5595       0.7500        0.5625  0.0715\n",
            "     29        0.5595       0.7500        0.5625  0.0712\n",
            "     30        0.5596       0.7500        0.5625  0.0711\n",
            "     31        0.5596       0.7500        0.5625  0.0726\n",
            "     32        0.5596       0.7500        0.5625  0.0770\n",
            "     33        0.5597       0.7500        0.5625  0.0731\n",
            "     34        0.5597       0.7500        0.5625  0.0719\n",
            "     35        0.5597       0.7500        0.5625  0.0752\n",
            "     36        0.5598       0.7500        0.5625  0.0719\n",
            "     37        0.5598       0.7500        0.5625  0.0765\n",
            "     38        0.5598       0.7500        0.5625  0.0725\n",
            "     39        0.5599       0.7500        0.5625  0.0731\n",
            "     40        0.5599       0.7500        0.5625  0.0716\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4315\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6167\u001b[0m  0.0703\n",
            "      2        \u001b[36m0.5851\u001b[0m       0.7500        \u001b[35m0.5942\u001b[0m  0.0723\n",
            "      3        0.5921       0.7500        \u001b[35m0.5674\u001b[0m  0.0719\n",
            "      4        \u001b[36m0.5582\u001b[0m       0.7500        0.5748  0.0717\n",
            "      5        0.5642       0.7500        \u001b[35m0.5623\u001b[0m  0.0741\n",
            "      6        0.5620       0.7500        0.5656  0.0717\n",
            "      7        0.5592       0.7500        0.5628  0.0720\n",
            "      8        0.5582       0.7500        0.5631  0.0746\n",
            "      9        0.5592       0.7500        0.5627  0.0746\n",
            "     10        0.5592       0.7500        \u001b[35m0.5623\u001b[0m  0.0809\n",
            "     11        0.5583       0.7500        0.5626  0.0717\n",
            "     12        0.5589       0.7500        0.5623  0.0739\n",
            "     13        0.5592       0.7500        0.5623  0.0722\n",
            "     14        0.5589       0.7500        0.5624  0.0718\n",
            "     15        0.5591       0.7500        0.5624  0.0719\n",
            "     16        0.5593       0.7500        0.5623  0.0715\n",
            "     17        0.5592       0.7500        0.5624  0.0716\n",
            "     18        0.5593       0.7500        0.5624  0.0720\n",
            "     19        0.5594       0.7500        0.5623  0.0712\n",
            "     20        0.5594       0.7500        0.5624  0.0723\n",
            "     21        0.5595       0.7500        0.5624  0.0746\n",
            "     22        0.5595       0.7500        0.5624  0.0723\n",
            "     23        0.5596       0.7500        0.5624  0.0720\n",
            "     24        0.5596       0.7500        0.5624  0.0756\n",
            "     25        0.5597       0.7500        0.5624  0.0712\n",
            "     26        0.5597       0.7500        0.5624  0.0713\n",
            "     27        0.5597       0.7500        0.5624  0.0711\n",
            "     28        0.5597       0.7500        0.5624  0.0719\n",
            "     29        0.5598       0.7500        0.5624  0.0718\n",
            "     30        0.5598       0.7500        0.5624  0.0715\n",
            "     31        0.5598       0.7500        0.5624  0.0845\n",
            "     32        0.5598       0.7500        0.5624  0.0728\n",
            "     33        0.5599       0.7500        0.5624  0.0733\n",
            "     34        0.5599       0.7500        0.5624  0.0726\n",
            "     35        0.5599       0.7500        0.5624  0.0788\n",
            "     36        0.5599       0.7500        0.5624  0.0720\n",
            "     37        0.5599       0.7500        0.5624  0.0762\n",
            "     38        0.5600       0.7500        0.5624  0.0715\n",
            "     39        0.5600       0.7500        0.5624  0.0722\n",
            "     40        0.5600       0.7500        0.5624  0.0753\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4678\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6247\u001b[0m  0.0751\n",
            "      2        \u001b[36m0.5853\u001b[0m       0.7500        \u001b[35m0.5932\u001b[0m  0.0717\n",
            "      3        0.5951       0.7500        \u001b[35m0.5689\u001b[0m  0.0713\n",
            "      4        \u001b[36m0.5637\u001b[0m       0.7500        0.5745  0.0717\n",
            "      5        0.5647       0.7500        \u001b[35m0.5625\u001b[0m  0.0719\n",
            "      6        \u001b[36m0.5632\u001b[0m       0.7500        0.5657  0.0715\n",
            "      7        0.5637       0.7500        0.5626  0.0727\n",
            "      8        \u001b[36m0.5607\u001b[0m       0.7500        0.5634  0.0718\n",
            "      9        0.5609       0.7500        0.5625  0.0716\n",
            "     10        0.5624       0.7500        \u001b[35m0.5623\u001b[0m  0.0732\n",
            "     11        0.5614       0.7500        0.5627  0.0755\n",
            "     12        0.5613       0.7500        \u001b[35m0.5623\u001b[0m  0.0724\n",
            "     13        0.5620       0.7500        \u001b[35m0.5623\u001b[0m  0.0730\n",
            "     14        0.5620       0.7500        0.5624  0.0717\n",
            "     15        0.5619       0.7500        0.5624  0.0710\n",
            "     16        0.5622       0.7500        0.5623  0.0712\n",
            "     17        0.5623       0.7500        0.5624  0.0720\n",
            "     18        0.5623       0.7500        0.5624  0.0714\n",
            "     19        0.5624       0.7500        0.5624  0.0724\n",
            "     20        0.5625       0.7500        0.5624  0.0786\n",
            "     21        0.5625       0.7500        0.5624  0.0733\n",
            "     22        0.5626       0.7500        0.5624  0.0721\n",
            "     23        0.5627       0.7500        0.5624  0.0715\n",
            "     24        0.5627       0.7500        0.5624  0.0755\n",
            "     25        0.5627       0.7500        0.5624  0.0713\n",
            "     26        0.5628       0.7500        0.5624  0.0730\n",
            "     27        0.5628       0.7500        0.5624  0.0712\n",
            "     28        0.5629       0.7500        0.5624  0.0711\n",
            "     29        0.5629       0.7500        0.5624  0.0718\n",
            "     30        0.5629       0.7500        0.5624  0.0742\n",
            "     31        0.5630       0.7500        0.5624  0.0712\n",
            "     32        0.5630       0.7500        0.5624  0.0718\n",
            "     33        0.5630       0.7500        0.5624  0.0713\n",
            "     34        0.5631       0.7500        0.5624  0.0729\n",
            "     35        0.5631       0.7500        0.5624  0.0715\n",
            "     36        0.5631       0.7500        0.5624  0.0716\n",
            "     37        0.5631       0.7500        0.5624  0.0729\n",
            "     38        0.5632       0.7500        0.5624  0.0755\n",
            "     39        0.5632       0.7500        0.5624  0.0721\n",
            "     40        0.5632       0.7500        0.5624  0.0741\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3693\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5892\u001b[0m  0.0757\n",
            "      2        \u001b[36m0.6044\u001b[0m       0.7500        0.6248  0.0722\n",
            "      3        0.6172       0.7500        \u001b[35m0.5624\u001b[0m  0.0728\n",
            "      4        \u001b[36m0.5679\u001b[0m       0.7500        0.5701  0.0726\n",
            "      5        \u001b[36m0.5665\u001b[0m       0.7500        0.5715  0.0738\n",
            "      6        0.5808       0.7500        0.5628  0.0724\n",
            "      7        \u001b[36m0.5660\u001b[0m       0.7500        0.5636  0.0789\n",
            "      8        0.5661       0.7500        0.5640  0.0798\n",
            "      9        0.5728       0.7500        0.5626  0.0703\n",
            "     10        0.5678       0.7500        \u001b[35m0.5624\u001b[0m  0.0747\n",
            "     11        0.5681       0.7500        0.5628  0.0817\n",
            "     12        0.5709       0.7500        0.5625  0.0730\n",
            "     13        0.5690       0.7500        \u001b[35m0.5623\u001b[0m  0.0713\n",
            "     14        0.5695       0.7500        0.5626  0.0710\n",
            "     15        0.5706       0.7500        0.5624  0.0714\n",
            "     16        0.5699       0.7500        0.5624  0.0716\n",
            "     17        0.5703       0.7500        0.5625  0.0729\n",
            "     18        0.5707       0.7500        0.5624  0.0725\n",
            "     19        0.5704       0.7500        0.5624  0.0715\n",
            "     20        0.5707       0.7500        0.5624  0.0716\n",
            "     21        0.5709       0.7500        0.5624  0.0873\n",
            "     22        0.5709       0.7500        0.5624  0.0726\n",
            "     23        0.5710       0.7500        0.5624  0.0720\n",
            "     24        0.5711       0.7500        0.5624  0.0773\n",
            "     25        0.5712       0.7500        0.5624  0.0720\n",
            "     26        0.5713       0.7500        0.5624  0.0744\n",
            "     27        0.5713       0.7500        0.5624  0.0716\n",
            "     28        0.5714       0.7500        0.5624  0.0716\n",
            "     29        0.5715       0.7500        0.5624  0.0713\n",
            "     30        0.5715       0.7500        0.5624  0.0714\n",
            "     31        0.5715       0.7500        0.5624  0.0724\n",
            "     32        0.5716       0.7500        0.5624  0.0711\n",
            "     33        0.5716       0.7500        0.5624  0.0727\n",
            "     34        0.5717       0.7500        0.5624  0.0736\n",
            "     35        0.5717       0.7500        0.5624  0.0727\n",
            "     36        0.5718       0.7500        0.5624  0.0726\n",
            "     37        0.5718       0.7500        0.5624  0.0734\n",
            "     38        0.5718       0.7500        0.5624  0.0707\n",
            "     39        0.5719       0.7500        0.5624  0.0720\n",
            "     40        0.5719       0.7500        0.5624  0.0717\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5922\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5707\u001b[0m  0.0938\n",
            "      2        \u001b[36m0.5791\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0958\n",
            "      3        \u001b[36m0.5592\u001b[0m       0.7557        0.5603  0.0944\n",
            "      4        \u001b[36m0.5590\u001b[0m       0.7557        0.5573  0.0946\n",
            "      5        \u001b[36m0.5554\u001b[0m       0.7557        0.5561  0.0947\n",
            "      6        0.5555       0.7557        0.5565  0.0925\n",
            "      7        0.5557       0.7557        0.5561  0.0936\n",
            "      8        \u001b[36m0.5551\u001b[0m       0.7557        0.5561  0.0976\n",
            "      9        \u001b[36m0.5546\u001b[0m       0.7557        0.5561  0.0933\n",
            "     10        \u001b[36m0.5542\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0935\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5986\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5791\u001b[0m  0.0958\n",
            "      2        \u001b[36m0.5784\u001b[0m       0.7500        \u001b[35m0.5630\u001b[0m  0.0975\n",
            "      3        \u001b[36m0.5585\u001b[0m       0.7500        0.5650  0.0931\n",
            "      4        0.5589       0.7500        0.5636  0.0937\n",
            "      5        \u001b[36m0.5556\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0927\n",
            "      6        \u001b[36m0.5549\u001b[0m       0.7500        0.5631  0.0922\n",
            "      7        0.5558       0.7500        0.5626  0.0936\n",
            "      8        \u001b[36m0.5549\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0936\n",
            "      9        \u001b[36m0.5543\u001b[0m       0.7500        \u001b[35m0.5620\u001b[0m  0.0974\n",
            "     10        \u001b[36m0.5536\u001b[0m       0.7500        \u001b[35m0.5619\u001b[0m  0.0943\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6044\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5798\u001b[0m  0.0940\n",
            "      2        \u001b[36m0.5807\u001b[0m       0.7500        \u001b[35m0.5630\u001b[0m  0.0970\n",
            "      3        \u001b[36m0.5588\u001b[0m       0.7500        0.5654  0.0938\n",
            "      4        0.5592       0.7500        0.5635  0.0933\n",
            "      5        \u001b[36m0.5555\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0934\n",
            "      6        \u001b[36m0.5550\u001b[0m       0.7500        0.5630  0.0935\n",
            "      7        0.5554       0.7500        \u001b[35m0.5622\u001b[0m  0.0932\n",
            "      8        \u001b[36m0.5548\u001b[0m       0.7500        \u001b[35m0.5618\u001b[0m  0.0950\n",
            "      9        \u001b[36m0.5542\u001b[0m       0.7500        \u001b[35m0.5615\u001b[0m  0.0944\n",
            "     10        \u001b[36m0.5534\u001b[0m       0.7500        \u001b[35m0.5607\u001b[0m  0.0940\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5808\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5947\u001b[0m  0.0932\n",
            "      2        \u001b[36m0.5737\u001b[0m       0.7500        \u001b[35m0.5654\u001b[0m  0.0951\n",
            "      3        \u001b[36m0.5617\u001b[0m       0.7500        \u001b[35m0.5644\u001b[0m  0.0938\n",
            "      4        \u001b[36m0.5551\u001b[0m       0.7500        \u001b[35m0.5628\u001b[0m  0.0953\n",
            "      5        0.5551       0.7500        0.5640  0.0943\n",
            "      6        0.5560       0.7500        \u001b[35m0.5625\u001b[0m  0.0948\n",
            "      7        0.5553       0.7500        \u001b[35m0.5622\u001b[0m  0.0937\n",
            "      8        \u001b[36m0.5545\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0951\n",
            "      9        \u001b[36m0.5538\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0980\n",
            "     10        \u001b[36m0.5534\u001b[0m       0.7500        0.5623  0.0940\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6091\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5635\u001b[0m  0.0931\n",
            "      2        \u001b[36m0.5727\u001b[0m       0.7500        0.5655  0.0947\n",
            "      3        \u001b[36m0.5592\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0940\n",
            "      4        \u001b[36m0.5573\u001b[0m       0.7500        0.5631  0.0929\n",
            "      5        \u001b[36m0.5569\u001b[0m       0.7500        0.5625  0.0942\n",
            "      6        \u001b[36m0.5561\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0939\n",
            "      7        \u001b[36m0.5558\u001b[0m       0.7500        0.5624  0.0934\n",
            "      8        \u001b[36m0.5555\u001b[0m       0.7500        \u001b[35m0.5620\u001b[0m  0.0939\n",
            "      9        \u001b[36m0.5550\u001b[0m       0.7500        \u001b[35m0.5618\u001b[0m  0.0973\n",
            "     10        \u001b[36m0.5544\u001b[0m       0.7500        \u001b[35m0.5617\u001b[0m  0.0974\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6117\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5638\u001b[0m  0.0951\n",
            "      2        \u001b[36m0.5785\u001b[0m       0.7500        \u001b[35m0.5628\u001b[0m  0.0971\n",
            "      3        \u001b[36m0.5601\u001b[0m       0.7500        0.5641  0.0940\n",
            "      4        0.5615       0.7500        0.5636  0.0960\n",
            "      5        0.5609       0.7500        \u001b[35m0.5624\u001b[0m  0.0955\n",
            "      6        0.5605       0.7500        0.5625  0.0942\n",
            "      7        0.5603       0.7500        0.5624  0.0946\n",
            "      8        \u001b[36m0.5598\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0940\n",
            "      9        \u001b[36m0.5598\u001b[0m       0.7500        0.5624  0.0952\n",
            "     10        0.5598       0.7500        0.5624  0.0966\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6351\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5767\u001b[0m  0.0943\n",
            "      2        \u001b[36m0.5838\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0940\n",
            "      3        \u001b[36m0.5560\u001b[0m       0.7500        0.5666  0.0929\n",
            "      4        0.5602       0.7500        0.5638  0.0925\n",
            "      5        0.5575       0.7500        \u001b[35m0.5624\u001b[0m  0.0925\n",
            "      6        0.5566       0.7500        0.5630  0.0926\n",
            "      7        \u001b[36m0.5559\u001b[0m       0.7500        0.5626  0.0949\n",
            "      8        \u001b[36m0.5550\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.1023\n",
            "      9        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0944\n",
            "     10        0.5550       0.7500        0.5623  0.0972\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6386\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5651\u001b[0m  0.0941\n",
            "      2        \u001b[36m0.5838\u001b[0m       0.7500        \u001b[35m0.5647\u001b[0m  0.0940\n",
            "      3        \u001b[36m0.5564\u001b[0m       0.7500        \u001b[35m0.5639\u001b[0m  0.0937\n",
            "      4        0.5583       0.7500        0.5641  0.0937\n",
            "      5        0.5575       0.7500        \u001b[35m0.5624\u001b[0m  0.0938\n",
            "      6        \u001b[36m0.5562\u001b[0m       0.7500        0.5627  0.0918\n",
            "      7        \u001b[36m0.5560\u001b[0m       0.7500        0.5628  0.0955\n",
            "      8        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0930\n",
            "      9        \u001b[36m0.5548\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0944\n",
            "     10        \u001b[36m0.5547\u001b[0m       0.7500        0.5623  0.0942\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6151\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5623\u001b[0m  0.0967\n",
            "      2        \u001b[36m0.5729\u001b[0m       0.7500        0.5640  0.0953\n",
            "      3        \u001b[36m0.5600\u001b[0m       0.7500        0.5624  0.1032\n",
            "      4        \u001b[36m0.5579\u001b[0m       0.7500        0.5628  0.0927\n",
            "      5        \u001b[36m0.5576\u001b[0m       0.7500        0.5624  0.0925\n",
            "      6        \u001b[36m0.5570\u001b[0m       0.7500        0.5624  0.0930\n",
            "      7        \u001b[36m0.5568\u001b[0m       0.7500        0.5625  0.0932\n",
            "      8        \u001b[36m0.5566\u001b[0m       0.7500        0.5624  0.0932\n",
            "      9        \u001b[36m0.5562\u001b[0m       0.7500        0.5623  0.0942\n",
            "     10        \u001b[36m0.5558\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0929\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6056\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5623\u001b[0m  0.0975\n",
            "      2        \u001b[36m0.5767\u001b[0m       0.7500        0.5666  0.0938\n",
            "      3        \u001b[36m0.5634\u001b[0m       0.7500        0.5628  0.0928\n",
            "      4        \u001b[36m0.5579\u001b[0m       0.7500        0.5623  0.0934\n",
            "      5        \u001b[36m0.5569\u001b[0m       0.7500        0.5625  0.0922\n",
            "      6        \u001b[36m0.5568\u001b[0m       0.7500        0.5630  0.0958\n",
            "      7        0.5571       0.7500        0.5633  0.0945\n",
            "      8        0.5570       0.7500        0.5634  0.0952\n",
            "      9        \u001b[36m0.5567\u001b[0m       0.7500        0.5633  0.0939\n",
            "     10        \u001b[36m0.5560\u001b[0m       0.7500        0.5630  0.0934\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7841\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5450\u001b[0m  0.0884\n",
            "      2        \u001b[36m0.6787\u001b[0m       0.7557        \u001b[35m0.5172\u001b[0m  0.0884\n",
            "      3        \u001b[36m0.4958\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.4619\u001b[0m  0.0874\n",
            "      4        \u001b[36m0.4145\u001b[0m       \u001b[32m0.7841\u001b[0m        \u001b[35m0.4284\u001b[0m  0.0875\n",
            "      5        \u001b[36m0.3323\u001b[0m       0.7330        0.4818  0.0874\n",
            "      6        \u001b[36m0.3102\u001b[0m       0.7841        0.5090  0.0874\n",
            "      7        \u001b[36m0.2796\u001b[0m       0.7670        0.4786  0.0872\n",
            "      8        \u001b[36m0.2505\u001b[0m       0.7784        0.5027  0.0893\n",
            "      9        \u001b[36m0.2257\u001b[0m       0.7841        0.5575  0.0902\n",
            "     10        \u001b[36m0.2158\u001b[0m       0.7443        0.6104  0.0904\n",
            "     11        \u001b[36m0.2022\u001b[0m       0.7443        0.6178  0.0888\n",
            "     12        \u001b[36m0.1679\u001b[0m       \u001b[32m0.8011\u001b[0m        0.5248  0.0870\n",
            "     13        \u001b[36m0.1588\u001b[0m       0.7784        0.6662  0.0932\n",
            "     14        \u001b[36m0.1403\u001b[0m       0.7670        0.6599  0.0875\n",
            "     15        0.1526       0.7216        1.0868  0.0877\n",
            "     16        0.2784       \u001b[32m0.8068\u001b[0m        0.5617  0.0874\n",
            "     17        0.1827       \u001b[32m0.8125\u001b[0m        0.5737  0.0883\n",
            "     18        0.1417       0.7273        0.7443  0.0883\n",
            "     19        0.1422       0.7614        0.6777  0.0872\n",
            "     20        \u001b[36m0.1020\u001b[0m       0.7557        0.8052  0.0886\n",
            "     21        \u001b[36m0.0906\u001b[0m       0.7784        0.7627  0.0895\n",
            "     22        \u001b[36m0.0614\u001b[0m       0.7500        0.8710  0.0921\n",
            "     23        0.0643       0.7614        0.9052  0.0907\n",
            "     24        \u001b[36m0.0511\u001b[0m       0.7500        0.9014  0.0890\n",
            "     25        \u001b[36m0.0430\u001b[0m       0.7386        0.9533  0.0874\n",
            "     26        \u001b[36m0.0409\u001b[0m       0.7670        0.9296  0.0871\n",
            "     27        \u001b[36m0.0395\u001b[0m       0.7557        0.9443  0.0872\n",
            "     28        \u001b[36m0.0372\u001b[0m       0.7500        0.9743  0.0883\n",
            "     29        \u001b[36m0.0335\u001b[0m       0.7784        0.9293  0.0885\n",
            "     30        \u001b[36m0.0280\u001b[0m       0.7727        0.9967  0.0883\n",
            "     31        0.0289       0.7784        0.9868  0.0909\n",
            "     32        \u001b[36m0.0252\u001b[0m       0.7614        1.0340  0.0872\n",
            "     33        \u001b[36m0.0240\u001b[0m       0.7727        1.0357  0.0888\n",
            "     34        \u001b[36m0.0228\u001b[0m       0.7614        1.0768  0.0907\n",
            "     35        0.0229       0.7727        1.0699  0.0912\n",
            "     36        \u001b[36m0.0220\u001b[0m       0.7727        1.1021  0.0891\n",
            "     37        0.0221       0.7727        1.1057  0.0876\n",
            "     38        \u001b[36m0.0212\u001b[0m       0.7727        1.1277  0.0891\n",
            "     39        0.0212       0.7727        1.1422  0.0889\n",
            "     40        \u001b[36m0.0209\u001b[0m       0.7670        1.1465  0.0895\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7874\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5664\u001b[0m  0.0879\n",
            "      2        \u001b[36m0.6613\u001b[0m       0.7500        \u001b[35m0.5496\u001b[0m  0.0881\n",
            "      3        \u001b[36m0.5618\u001b[0m       0.7500        \u001b[35m0.5394\u001b[0m  0.0874\n",
            "      4        \u001b[36m0.4573\u001b[0m       \u001b[32m0.8068\u001b[0m        \u001b[35m0.4257\u001b[0m  0.0887\n",
            "      5        \u001b[36m0.3468\u001b[0m       0.8068        \u001b[35m0.4144\u001b[0m  0.0877\n",
            "      6        \u001b[36m0.2982\u001b[0m       0.7898        0.4587  0.0915\n",
            "      7        \u001b[36m0.2555\u001b[0m       0.7727        0.4764  0.0905\n",
            "      8        \u001b[36m0.2234\u001b[0m       0.7955        0.4672  0.0900\n",
            "      9        \u001b[36m0.2123\u001b[0m       0.7784        0.5326  0.0914\n",
            "     10        0.2163       \u001b[32m0.8125\u001b[0m        0.4675  0.0884\n",
            "     11        0.2220       0.7898        0.4639  0.0893\n",
            "     12        \u001b[36m0.1859\u001b[0m       0.7841        0.5212  0.0898\n",
            "     13        \u001b[36m0.1562\u001b[0m       0.7727        0.5242  0.0882\n",
            "     14        \u001b[36m0.1343\u001b[0m       0.7898        0.5785  0.0918\n",
            "     15        \u001b[36m0.1280\u001b[0m       0.7727        0.5375  0.0889\n",
            "     16        \u001b[36m0.0851\u001b[0m       0.7784        0.5473  0.0890\n",
            "     17        \u001b[36m0.0722\u001b[0m       \u001b[32m0.8295\u001b[0m        0.5613  0.0905\n",
            "     18        \u001b[36m0.0533\u001b[0m       0.7841        0.6174  0.0877\n",
            "     19        \u001b[36m0.0470\u001b[0m       0.7841        0.6378  0.0899\n",
            "     20        \u001b[36m0.0387\u001b[0m       0.8011        0.6775  0.0888\n",
            "     21        \u001b[36m0.0361\u001b[0m       0.8068        0.6970  0.0875\n",
            "     22        \u001b[36m0.0331\u001b[0m       0.7898        0.7281  0.0878\n",
            "     23        \u001b[36m0.0310\u001b[0m       0.8068        0.7487  0.0885\n",
            "     24        \u001b[36m0.0299\u001b[0m       0.8068        0.7545  0.0887\n",
            "     25        \u001b[36m0.0284\u001b[0m       0.8011        0.7295  0.0894\n",
            "     26        \u001b[36m0.0271\u001b[0m       0.7955        0.7456  0.0876\n",
            "     27        \u001b[36m0.0260\u001b[0m       0.8125        0.7669  0.0877\n",
            "     28        \u001b[36m0.0249\u001b[0m       0.8125        0.7789  0.0901\n",
            "     29        \u001b[36m0.0241\u001b[0m       0.8125        0.7846  0.0879\n",
            "     30        \u001b[36m0.0237\u001b[0m       0.8068        0.7875  0.0906\n",
            "     31        \u001b[36m0.0232\u001b[0m       0.8239        0.7980  0.0893\n",
            "     32        0.0236       0.8182        0.8091  0.0893\n",
            "     33        0.0233       0.8011        0.8208  0.0886\n",
            "     34        \u001b[36m0.0226\u001b[0m       0.8068        0.8534  0.0906\n",
            "     35        \u001b[36m0.0220\u001b[0m       0.8182        0.8695  0.0895\n",
            "     36        \u001b[36m0.0217\u001b[0m       0.8125        0.8778  0.0916\n",
            "     37        \u001b[36m0.0216\u001b[0m       0.8125        0.8863  0.0881\n",
            "     38        0.0220       0.8011        0.8669  0.0879\n",
            "     39        \u001b[36m0.0216\u001b[0m       0.7955        0.8706  0.0897\n",
            "     40        \u001b[36m0.0210\u001b[0m       0.8011        0.8833  0.0881\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5486\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6054\u001b[0m  0.0870\n",
            "      2        \u001b[36m0.6365\u001b[0m       0.7500        \u001b[35m0.5636\u001b[0m  0.0912\n",
            "      3        \u001b[36m0.5287\u001b[0m       \u001b[32m0.7784\u001b[0m        \u001b[35m0.4258\u001b[0m  0.0887\n",
            "      4        \u001b[36m0.4204\u001b[0m       0.7216        0.5280  0.0883\n",
            "      5        \u001b[36m0.3695\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4030\u001b[0m  0.0880\n",
            "      6        \u001b[36m0.3143\u001b[0m       0.8125        0.4120  0.0905\n",
            "      7        \u001b[36m0.2940\u001b[0m       0.7670        0.4320  0.0889\n",
            "      8        \u001b[36m0.2703\u001b[0m       \u001b[32m0.8182\u001b[0m        \u001b[35m0.3840\u001b[0m  0.0897\n",
            "      9        \u001b[36m0.2397\u001b[0m       \u001b[32m0.8409\u001b[0m        0.3861  0.0900\n",
            "     10        \u001b[36m0.2132\u001b[0m       0.8011        0.4422  0.0902\n",
            "     11        \u001b[36m0.2028\u001b[0m       0.8125        0.3978  0.0905\n",
            "     12        \u001b[36m0.1780\u001b[0m       0.8011        0.4283  0.0902\n",
            "     13        \u001b[36m0.1475\u001b[0m       0.8068        0.4288  0.0881\n",
            "     14        \u001b[36m0.1301\u001b[0m       0.8011        0.4464  0.0879\n",
            "     15        \u001b[36m0.1159\u001b[0m       0.8068        0.4757  0.0886\n",
            "     16        \u001b[36m0.1003\u001b[0m       0.7727        0.5641  0.0937\n",
            "     17        0.1015       0.7955        0.5116  0.0885\n",
            "     18        \u001b[36m0.0992\u001b[0m       0.8239        0.4821  0.0881\n",
            "     19        0.1113       0.7216        0.7054  0.0876\n",
            "     20        0.1203       0.8068        0.5240  0.0880\n",
            "     21        0.1327       0.7727        0.6096  0.0897\n",
            "     22        0.2290       0.8011        0.5291  0.0887\n",
            "     23        0.2592       0.7670        0.7471  0.0894\n",
            "     24        0.2193       0.7841        0.5035  0.0878\n",
            "     25        0.1625       0.7784        0.4953  0.0883\n",
            "     26        0.1136       0.7614        0.5567  0.0880\n",
            "     27        \u001b[36m0.0944\u001b[0m       0.7670        0.5173  0.0917\n",
            "     28        \u001b[36m0.0696\u001b[0m       0.7386        0.6246  0.0897\n",
            "     29        \u001b[36m0.0665\u001b[0m       0.7557        0.5917  0.0927\n",
            "     30        \u001b[36m0.0530\u001b[0m       0.7500        0.5680  0.0874\n",
            "     31        \u001b[36m0.0462\u001b[0m       0.7557        0.5854  0.0910\n",
            "     32        \u001b[36m0.0432\u001b[0m       0.7727        0.5910  0.0932\n",
            "     33        \u001b[36m0.0386\u001b[0m       0.7500        0.6081  0.0885\n",
            "     34        \u001b[36m0.0356\u001b[0m       0.7557        0.6162  0.0875\n",
            "     35        \u001b[36m0.0322\u001b[0m       0.7500        0.6395  0.0887\n",
            "     36        \u001b[36m0.0313\u001b[0m       0.7557        0.6442  0.0872\n",
            "     37        \u001b[36m0.0283\u001b[0m       0.7386        0.6669  0.0895\n",
            "     38        \u001b[36m0.0278\u001b[0m       0.7614        0.6675  0.0919\n",
            "     39        \u001b[36m0.0266\u001b[0m       0.7670        0.6738  0.0956\n",
            "     40        0.0271       0.7614        0.6806  0.0873\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7403\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5589\u001b[0m  0.0871\n",
            "      2        \u001b[36m0.6434\u001b[0m       0.7500        \u001b[35m0.5564\u001b[0m  0.0907\n",
            "      3        \u001b[36m0.5017\u001b[0m       \u001b[32m0.7841\u001b[0m        \u001b[35m0.4345\u001b[0m  0.0905\n",
            "      4        \u001b[36m0.3589\u001b[0m       \u001b[32m0.8068\u001b[0m        \u001b[35m0.3873\u001b[0m  0.0877\n",
            "      5        \u001b[36m0.3227\u001b[0m       0.8011        0.4044  0.0890\n",
            "      6        \u001b[36m0.2813\u001b[0m       0.7955        0.4258  0.0886\n",
            "      7        \u001b[36m0.2557\u001b[0m       0.8011        0.3949  0.0874\n",
            "      8        \u001b[36m0.2246\u001b[0m       0.7898        0.3994  0.0877\n",
            "      9        \u001b[36m0.2023\u001b[0m       0.8068        0.4356  0.0873\n",
            "     10        \u001b[36m0.1896\u001b[0m       0.7955        0.5633  0.0883\n",
            "     11        0.2109       0.7784        0.5161  0.0904\n",
            "     12        0.2342       0.7841        0.4346  0.0879\n",
            "     13        \u001b[36m0.1871\u001b[0m       0.7670        0.5646  0.0871\n",
            "     14        \u001b[36m0.1630\u001b[0m       0.7727        0.4634  0.0898\n",
            "     15        \u001b[36m0.1429\u001b[0m       0.7557        0.5664  0.0911\n",
            "     16        \u001b[36m0.1276\u001b[0m       0.7670        0.5513  0.0887\n",
            "     17        \u001b[36m0.1004\u001b[0m       0.7557        0.5791  0.0880\n",
            "     18        \u001b[36m0.0871\u001b[0m       0.7784        0.5861  0.0881\n",
            "     19        \u001b[36m0.0744\u001b[0m       0.7955        0.6171  0.0910\n",
            "     20        \u001b[36m0.0598\u001b[0m       0.7784        0.6898  0.0895\n",
            "     21        \u001b[36m0.0540\u001b[0m       0.7500        0.7311  0.0899\n",
            "     22        \u001b[36m0.0503\u001b[0m       0.7557        0.7469  0.0900\n",
            "     23        \u001b[36m0.0453\u001b[0m       0.7614        0.7503  0.0880\n",
            "     24        \u001b[36m0.0401\u001b[0m       0.7330        0.7862  0.0884\n",
            "     25        \u001b[36m0.0391\u001b[0m       0.7443        0.7970  0.0884\n",
            "     26        \u001b[36m0.0353\u001b[0m       0.7614        0.7701  0.0878\n",
            "     27        \u001b[36m0.0324\u001b[0m       0.7273        0.9283  0.0876\n",
            "     28        0.0346       0.7670        0.8124  0.0882\n",
            "     29        \u001b[36m0.0271\u001b[0m       0.7614        0.8265  0.0881\n",
            "     30        \u001b[36m0.0264\u001b[0m       0.7330        0.9507  0.0891\n",
            "     31        0.0282       0.7955        0.8384  0.0915\n",
            "     32        \u001b[36m0.0249\u001b[0m       0.7727        0.8604  0.0909\n",
            "     33        \u001b[36m0.0229\u001b[0m       0.7727        0.8418  0.0888\n",
            "     34        \u001b[36m0.0214\u001b[0m       0.7955        0.8457  0.0881\n",
            "     35        \u001b[36m0.0208\u001b[0m       0.7898        0.8552  0.0875\n",
            "     36        0.0215       0.7898        0.8807  0.0901\n",
            "     37        0.0228       0.7898        0.8811  0.0879\n",
            "     38        0.0227       0.7898        0.8926  0.0877\n",
            "     39        0.0222       0.7614        0.9576  0.0878\n",
            "     40        0.0238       0.7386        1.0136  0.0877\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.9049\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5933\u001b[0m  0.0922\n",
            "      2        \u001b[36m0.6848\u001b[0m       0.7500        \u001b[35m0.5579\u001b[0m  0.0906\n",
            "      3        \u001b[36m0.5693\u001b[0m       0.7500        0.5851  0.0897\n",
            "      4        \u001b[36m0.5331\u001b[0m       0.7443        0.5702  0.0872\n",
            "      5        \u001b[36m0.4442\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.5507\u001b[0m  0.0891\n",
            "      6        \u001b[36m0.3703\u001b[0m       0.7557        \u001b[35m0.5383\u001b[0m  0.0878\n",
            "      7        \u001b[36m0.2864\u001b[0m       \u001b[32m0.7841\u001b[0m        \u001b[35m0.5091\u001b[0m  0.0913\n",
            "      8        \u001b[36m0.2127\u001b[0m       0.7102        0.5595  0.0889\n",
            "      9        \u001b[36m0.1676\u001b[0m       \u001b[32m0.8011\u001b[0m        \u001b[35m0.5010\u001b[0m  0.0893\n",
            "     10        \u001b[36m0.1282\u001b[0m       \u001b[32m0.8068\u001b[0m        0.5446  0.0881\n",
            "     11        0.1284       0.8011        \u001b[35m0.4998\u001b[0m  0.0881\n",
            "     12        0.1302       0.6534        0.7664  0.0918\n",
            "     13        0.1762       0.7784        0.6038  0.0899\n",
            "     14        0.1626       0.7898        0.5867  0.0881\n",
            "     15        \u001b[36m0.1244\u001b[0m       0.7273        0.6732  0.0876\n",
            "     16        \u001b[36m0.1240\u001b[0m       0.7614        0.6948  0.0874\n",
            "     17        \u001b[36m0.0908\u001b[0m       0.7443        0.5937  0.0886\n",
            "     18        \u001b[36m0.0640\u001b[0m       0.7784        0.6009  0.0882\n",
            "     19        \u001b[36m0.0469\u001b[0m       0.7727        0.5845  0.0882\n",
            "     20        \u001b[36m0.0344\u001b[0m       0.7841        0.5903  0.0886\n",
            "     21        \u001b[36m0.0303\u001b[0m       0.7670        0.6096  0.0883\n",
            "     22        \u001b[36m0.0258\u001b[0m       0.7670        0.6280  0.0915\n",
            "     23        \u001b[36m0.0239\u001b[0m       0.7670        0.6470  0.0961\n",
            "     24        \u001b[36m0.0220\u001b[0m       0.7727        0.6595  0.0873\n",
            "     25        \u001b[36m0.0213\u001b[0m       0.7727        0.6704  0.0876\n",
            "     26        \u001b[36m0.0206\u001b[0m       0.7670        0.6788  0.0882\n",
            "     27        \u001b[36m0.0201\u001b[0m       0.7557        0.6969  0.0881\n",
            "     28        \u001b[36m0.0196\u001b[0m       0.7614        0.6986  0.0874\n",
            "     29        \u001b[36m0.0193\u001b[0m       0.7614        0.7046  0.0891\n",
            "     30        \u001b[36m0.0191\u001b[0m       0.7614        0.7142  0.0875\n",
            "     31        \u001b[36m0.0189\u001b[0m       0.7614        0.7196  0.0872\n",
            "     32        \u001b[36m0.0187\u001b[0m       0.7614        0.7281  0.0878\n",
            "     33        \u001b[36m0.0186\u001b[0m       0.7614        0.7357  0.0906\n",
            "     34        \u001b[36m0.0185\u001b[0m       0.7614        0.7414  0.0882\n",
            "     35        \u001b[36m0.0184\u001b[0m       0.7614        0.7465  0.0889\n",
            "     36        \u001b[36m0.0183\u001b[0m       0.7670        0.7508  0.0891\n",
            "     37        \u001b[36m0.0182\u001b[0m       0.7670        0.7556  0.0877\n",
            "     38        \u001b[36m0.0181\u001b[0m       0.7670        0.7600  0.0882\n",
            "     39        \u001b[36m0.0180\u001b[0m       0.7670        0.7639  0.0882\n",
            "     40        \u001b[36m0.0180\u001b[0m       0.7670        0.7677  0.0898\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.8804\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6018\u001b[0m  0.0875\n",
            "      2        \u001b[36m0.8427\u001b[0m       0.6818        \u001b[35m0.5975\u001b[0m  0.0908\n",
            "      3        \u001b[36m0.5356\u001b[0m       \u001b[32m0.7614\u001b[0m        \u001b[35m0.5412\u001b[0m  0.0893\n",
            "      4        \u001b[36m0.5177\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.4893\u001b[0m  0.0874\n",
            "      5        \u001b[36m0.4559\u001b[0m       0.7614        0.5217  0.0878\n",
            "      6        \u001b[36m0.3620\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4268\u001b[0m  0.0943\n",
            "      7        \u001b[36m0.3008\u001b[0m       0.7841        0.4305  0.0891\n",
            "      8        \u001b[36m0.2727\u001b[0m       0.7386        0.5358  0.0875\n",
            "      9        \u001b[36m0.2412\u001b[0m       0.7841        0.4311  0.0890\n",
            "     10        \u001b[36m0.1967\u001b[0m       0.7727        0.4513  0.0893\n",
            "     11        \u001b[36m0.1676\u001b[0m       0.7557        0.5745  0.0887\n",
            "     12        \u001b[36m0.1616\u001b[0m       0.7898        0.4492  0.0872\n",
            "     13        \u001b[36m0.1244\u001b[0m       0.7955        0.4623  0.0874\n",
            "     14        \u001b[36m0.1153\u001b[0m       0.7614        0.5986  0.0879\n",
            "     15        \u001b[36m0.1092\u001b[0m       \u001b[32m0.8239\u001b[0m        0.4598  0.0889\n",
            "     16        \u001b[36m0.0906\u001b[0m       0.7784        0.5082  0.0890\n",
            "     17        \u001b[36m0.0768\u001b[0m       0.8068        0.4989  0.0886\n",
            "     18        \u001b[36m0.0589\u001b[0m       0.8011        0.5588  0.0889\n",
            "     19        \u001b[36m0.0529\u001b[0m       0.7898        0.6001  0.0891\n",
            "     20        0.0583       0.8125        0.5337  0.0880\n",
            "     21        0.0610       0.7784        0.6214  0.0876\n",
            "     22        0.0734       0.7898        0.6661  0.0896\n",
            "     23        0.0698       0.8182        0.5333  0.0867\n",
            "     24        0.0811       0.7841        0.7914  0.0892\n",
            "     25        0.0957       0.8125        0.5816  0.0877\n",
            "     26        0.0567       0.8011        0.5739  0.0879\n",
            "     27        \u001b[36m0.0496\u001b[0m       0.7955        0.6126  0.0909\n",
            "     28        \u001b[36m0.0358\u001b[0m       0.8068        0.5764  0.0875\n",
            "     29        \u001b[36m0.0354\u001b[0m       0.7727        0.6260  0.0877\n",
            "     30        \u001b[36m0.0337\u001b[0m       0.8125        0.6147  0.0875\n",
            "     31        \u001b[36m0.0259\u001b[0m       0.7898        0.6080  0.0889\n",
            "     32        \u001b[36m0.0235\u001b[0m       0.8125        0.6029  0.0911\n",
            "     33        \u001b[36m0.0216\u001b[0m       0.8125        0.6305  0.0883\n",
            "     34        \u001b[36m0.0203\u001b[0m       0.8182        0.6467  0.0885\n",
            "     35        \u001b[36m0.0197\u001b[0m       0.8182        0.6478  0.0907\n",
            "     36        \u001b[36m0.0191\u001b[0m       \u001b[32m0.8295\u001b[0m        0.6516  0.0882\n",
            "     37        \u001b[36m0.0182\u001b[0m       0.8182        0.6591  0.0878\n",
            "     38        \u001b[36m0.0174\u001b[0m       0.8125        0.6635  0.0896\n",
            "     39        \u001b[36m0.0171\u001b[0m       0.8239        0.6706  0.0885\n",
            "     40        \u001b[36m0.0165\u001b[0m       0.8239        0.6742  0.0873\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.8225\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6114\u001b[0m  0.0887\n",
            "      2        \u001b[36m0.8340\u001b[0m       0.7500        \u001b[35m0.5611\u001b[0m  0.0871\n",
            "      3        \u001b[36m0.5524\u001b[0m       0.7500        0.5909  0.0908\n",
            "      4        0.5994       0.7159        0.6026  0.0924\n",
            "      5        \u001b[36m0.4973\u001b[0m       0.7330        0.5746  0.0878\n",
            "      6        \u001b[36m0.3972\u001b[0m       0.7500        0.5721  0.0874\n",
            "      7        \u001b[36m0.3361\u001b[0m       0.7330        0.5892  0.0900\n",
            "      8        \u001b[36m0.2814\u001b[0m       \u001b[32m0.7670\u001b[0m        \u001b[35m0.5480\u001b[0m  0.0913\n",
            "      9        \u001b[36m0.2162\u001b[0m       0.7500        0.5829  0.0939\n",
            "     10        \u001b[36m0.1838\u001b[0m       0.7045        0.6624  0.0912\n",
            "     11        \u001b[36m0.1728\u001b[0m       0.7386        0.6119  0.0885\n",
            "     12        \u001b[36m0.1409\u001b[0m       0.7330        0.6924  0.0907\n",
            "     13        \u001b[36m0.1169\u001b[0m       0.6875        0.7983  0.0882\n",
            "     14        \u001b[36m0.1163\u001b[0m       0.7614        0.6683  0.0885\n",
            "     15        \u001b[36m0.0759\u001b[0m       0.7557        0.7043  0.0885\n",
            "     16        \u001b[36m0.0586\u001b[0m       0.7557        0.7504  0.0914\n",
            "     17        \u001b[36m0.0404\u001b[0m       0.7273        0.7850  0.0899\n",
            "     18        \u001b[36m0.0335\u001b[0m       0.7500        0.8549  0.0876\n",
            "     19        \u001b[36m0.0289\u001b[0m       0.7159        0.9092  0.0913\n",
            "     20        \u001b[36m0.0257\u001b[0m       0.7216        0.9231  0.0892\n",
            "     21        \u001b[36m0.0226\u001b[0m       0.7273        0.9685  0.0876\n",
            "     22        \u001b[36m0.0205\u001b[0m       0.7330        1.0024  0.0874\n",
            "     23        \u001b[36m0.0198\u001b[0m       0.7216        1.0284  0.0874\n",
            "     24        \u001b[36m0.0190\u001b[0m       0.7330        1.0677  0.0877\n",
            "     25        \u001b[36m0.0182\u001b[0m       0.7330        1.1056  0.0877\n",
            "     26        \u001b[36m0.0175\u001b[0m       0.7216        1.1237  0.0874\n",
            "     27        \u001b[36m0.0171\u001b[0m       0.7273        1.1310  0.0912\n",
            "     28        \u001b[36m0.0169\u001b[0m       0.7330        1.1381  0.0888\n",
            "     29        \u001b[36m0.0167\u001b[0m       0.7330        1.1386  0.0888\n",
            "     30        \u001b[36m0.0166\u001b[0m       0.7386        1.1529  0.0933\n",
            "     31        \u001b[36m0.0164\u001b[0m       0.7330        1.1699  0.0924\n",
            "     32        \u001b[36m0.0162\u001b[0m       0.7330        1.1847  0.0871\n",
            "     33        \u001b[36m0.0162\u001b[0m       0.7386        1.1966  0.0887\n",
            "     34        \u001b[36m0.0160\u001b[0m       0.7386        1.2073  0.0877\n",
            "     35        \u001b[36m0.0160\u001b[0m       0.7386        1.2160  0.0883\n",
            "     36        \u001b[36m0.0159\u001b[0m       0.7386        1.2262  0.0893\n",
            "     37        \u001b[36m0.0159\u001b[0m       0.7386        1.2356  0.0890\n",
            "     38        \u001b[36m0.0158\u001b[0m       0.7386        1.2458  0.0887\n",
            "     39        \u001b[36m0.0158\u001b[0m       0.7386        1.2558  0.0890\n",
            "     40        \u001b[36m0.0158\u001b[0m       0.7386        1.2651  0.0877\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7147\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5708\u001b[0m  0.0872\n",
            "      2        \u001b[36m0.7236\u001b[0m       0.7500        \u001b[35m0.5661\u001b[0m  0.0876\n",
            "      3        \u001b[36m0.6092\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0884\n",
            "      4        \u001b[36m0.6011\u001b[0m       0.7500        0.5713  0.0911\n",
            "      5        \u001b[36m0.5470\u001b[0m       0.7500        \u001b[35m0.5341\u001b[0m  0.0897\n",
            "      6        \u001b[36m0.4999\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5072\u001b[0m  0.0872\n",
            "      7        \u001b[36m0.4401\u001b[0m       \u001b[32m0.7614\u001b[0m        \u001b[35m0.4642\u001b[0m  0.0875\n",
            "      8        \u001b[36m0.3803\u001b[0m       \u001b[32m0.7898\u001b[0m        \u001b[35m0.4244\u001b[0m  0.0878\n",
            "      9        \u001b[36m0.3366\u001b[0m       \u001b[32m0.8239\u001b[0m        \u001b[35m0.4213\u001b[0m  0.0891\n",
            "     10        \u001b[36m0.3181\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m0.3981\u001b[0m  0.0881\n",
            "     11        \u001b[36m0.2872\u001b[0m       \u001b[32m0.8466\u001b[0m        \u001b[35m0.3892\u001b[0m  0.0878\n",
            "     12        \u001b[36m0.2775\u001b[0m       0.8295        0.3984  0.0881\n",
            "     13        \u001b[36m0.2362\u001b[0m       0.8409        \u001b[35m0.3687\u001b[0m  0.0892\n",
            "     14        \u001b[36m0.2263\u001b[0m       0.8011        0.4515  0.0879\n",
            "     15        0.2537       0.7955        0.4829  0.0893\n",
            "     16        0.2310       \u001b[32m0.8636\u001b[0m        \u001b[35m0.3500\u001b[0m  0.0877\n",
            "     17        \u001b[36m0.2038\u001b[0m       0.8295        0.3656  0.0896\n",
            "     18        0.2051       0.8409        0.3885  0.0873\n",
            "     19        0.2161       0.7841        0.5350  0.0866\n",
            "     20        0.2635       0.8466        0.3677  0.0895\n",
            "     21        \u001b[36m0.1887\u001b[0m       0.8523        0.3597  0.0885\n",
            "     22        \u001b[36m0.1788\u001b[0m       0.7784        0.5261  0.0903\n",
            "     23        0.1929       0.8466        0.3921  0.0894\n",
            "     24        \u001b[36m0.1383\u001b[0m       0.8352        0.4469  0.0886\n",
            "     25        \u001b[36m0.1258\u001b[0m       0.8182        0.4533  0.0879\n",
            "     26        \u001b[36m0.1250\u001b[0m       0.8352        0.4502  0.0875\n",
            "     27        0.1298       0.8011        0.4865  0.0879\n",
            "     28        \u001b[36m0.1229\u001b[0m       0.8523        0.4578  0.0889\n",
            "     29        \u001b[36m0.0873\u001b[0m       0.8352        0.4906  0.0879\n",
            "     30        \u001b[36m0.0835\u001b[0m       0.8466        0.4466  0.0902\n",
            "     31        \u001b[36m0.0683\u001b[0m       0.8409        0.4346  0.0893\n",
            "     32        \u001b[36m0.0633\u001b[0m       0.8580        0.4605  0.0887\n",
            "     33        \u001b[36m0.0611\u001b[0m       0.8295        0.5213  0.0892\n",
            "     34        \u001b[36m0.0565\u001b[0m       0.8182        0.5523  0.0915\n",
            "     35        0.0596       0.8295        0.5952  0.0896\n",
            "     36        \u001b[36m0.0556\u001b[0m       0.7841        0.6096  0.0879\n",
            "     37        0.0681       0.8352        0.5306  0.0919\n",
            "     38        \u001b[36m0.0541\u001b[0m       0.8068        0.6579  0.0876\n",
            "     39        0.0721       0.7784        0.7528  0.0874\n",
            "     40        0.1026       0.7045        0.8940  0.0874\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.0647\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5937\u001b[0m  0.0877\n",
            "      2        \u001b[36m0.7411\u001b[0m       0.7500        \u001b[35m0.5600\u001b[0m  0.0894\n",
            "      3        \u001b[36m0.5826\u001b[0m       0.7500        \u001b[35m0.5227\u001b[0m  0.0879\n",
            "      4        \u001b[36m0.5195\u001b[0m       0.6818        0.5568  0.0884\n",
            "      5        \u001b[36m0.4160\u001b[0m       \u001b[32m0.7841\u001b[0m        \u001b[35m0.3858\u001b[0m  0.0913\n",
            "      6        \u001b[36m0.3408\u001b[0m       \u001b[32m0.8125\u001b[0m        0.4037  0.0879\n",
            "      7        \u001b[36m0.3208\u001b[0m       0.7557        0.4876  0.0891\n",
            "      8        \u001b[36m0.2836\u001b[0m       0.8011        0.3967  0.0874\n",
            "      9        \u001b[36m0.2421\u001b[0m       0.8011        0.4147  0.0897\n",
            "     10        \u001b[36m0.2403\u001b[0m       0.7500        0.5364  0.0875\n",
            "     11        \u001b[36m0.2385\u001b[0m       0.8125        0.4307  0.0870\n",
            "     12        \u001b[36m0.1999\u001b[0m       \u001b[32m0.8239\u001b[0m        0.4302  0.0887\n",
            "     13        \u001b[36m0.1847\u001b[0m       0.7443        0.6295  0.0942\n",
            "     14        0.2025       \u001b[32m0.8295\u001b[0m        0.5597  0.0885\n",
            "     15        \u001b[36m0.1583\u001b[0m       0.7955        0.5304  0.0878\n",
            "     16        \u001b[36m0.1430\u001b[0m       0.7898        0.5095  0.0940\n",
            "     17        \u001b[36m0.1201\u001b[0m       0.7670        0.5668  0.0930\n",
            "     18        \u001b[36m0.1135\u001b[0m       0.7898        0.5544  0.0871\n",
            "     19        \u001b[36m0.0892\u001b[0m       0.7955        0.5580  0.0874\n",
            "     20        \u001b[36m0.0729\u001b[0m       0.7955        0.5920  0.0882\n",
            "     21        0.0898       0.8011        0.6380  0.0890\n",
            "     22        0.0799       0.8011        0.5663  0.0906\n",
            "     23        0.0740       0.7614        0.6442  0.0892\n",
            "     24        0.0923       0.7841        0.8241  0.0893\n",
            "     25        0.1254       0.7500        0.6932  0.0871\n",
            "     26        0.1277       0.8068        0.6633  0.0882\n",
            "     27        0.0986       0.7841        0.6611  0.0885\n",
            "     28        \u001b[36m0.0708\u001b[0m       0.8011        0.6678  0.0886\n",
            "     29        \u001b[36m0.0617\u001b[0m       0.7614        0.8488  0.0912\n",
            "     30        0.0668       0.7727        0.6854  0.0918\n",
            "     31        \u001b[36m0.0470\u001b[0m       0.7727        0.7171  0.0905\n",
            "     32        0.0604       0.7841        0.7766  0.0879\n",
            "     33        0.0957       0.6989        1.2348  0.0880\n",
            "     34        0.1358       0.7784        1.1302  0.0884\n",
            "     35        0.1380       0.6932        1.0989  0.0911\n",
            "     36        0.1116       0.7784        0.8714  0.0900\n",
            "     37        0.1508       0.6420        1.4286  0.0879\n",
            "     38        0.1622       0.7727        1.0589  0.0883\n",
            "     39        0.1951       0.6648        1.5910  0.0878\n",
            "     40        0.2343       0.7898        1.1754  0.0891\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.9014\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5737\u001b[0m  0.0868\n",
            "      2        \u001b[36m0.8765\u001b[0m       0.7500        \u001b[35m0.5650\u001b[0m  0.0879\n",
            "      3        \u001b[36m0.5858\u001b[0m       0.7500        0.5723  0.0876\n",
            "      4        0.6419       0.7330        \u001b[35m0.4865\u001b[0m  0.0890\n",
            "      5        \u001b[36m0.3914\u001b[0m       \u001b[32m0.7955\u001b[0m        \u001b[35m0.4311\u001b[0m  0.0898\n",
            "      6        \u001b[36m0.3262\u001b[0m       \u001b[32m0.8011\u001b[0m        \u001b[35m0.3853\u001b[0m  0.0909\n",
            "      7        \u001b[36m0.2846\u001b[0m       \u001b[32m0.8239\u001b[0m        0.3998  0.0884\n",
            "      8        \u001b[36m0.2748\u001b[0m       0.7898        0.3945  0.0891\n",
            "      9        \u001b[36m0.2537\u001b[0m       0.8239        0.4737  0.0879\n",
            "     10        0.2724       0.7841        0.4427  0.0876\n",
            "     11        \u001b[36m0.2516\u001b[0m       0.8239        0.4150  0.0905\n",
            "     12        \u001b[36m0.2115\u001b[0m       0.8068        0.3883  0.0896\n",
            "     13        \u001b[36m0.2010\u001b[0m       0.8239        0.4289  0.0900\n",
            "     14        \u001b[36m0.1793\u001b[0m       0.7955        0.4385  0.0878\n",
            "     15        \u001b[36m0.1781\u001b[0m       0.7670        0.6282  0.0876\n",
            "     16        0.2298       0.7727        0.6461  0.0887\n",
            "     17        0.2481       0.7614        0.9377  0.0895\n",
            "     18        0.3187       0.7045        1.0946  0.0875\n",
            "     19        0.4266       0.7500        1.1284  0.0891\n",
            "     20        0.5522       0.7500        0.9054  0.0915\n",
            "     21        0.3824       0.7614        0.6478  0.0898\n",
            "     22        0.2771       0.8011        0.5320  0.0890\n",
            "     23        0.1830       0.7784        0.4867  0.0876\n",
            "     24        \u001b[36m0.1412\u001b[0m       0.7784        0.4566  0.0872\n",
            "     25        \u001b[36m0.1240\u001b[0m       0.7841        0.4614  0.0872\n",
            "     26        \u001b[36m0.1140\u001b[0m       0.8011        0.5094  0.0876\n",
            "     27        \u001b[36m0.1020\u001b[0m       0.7841        0.4939  0.0919\n",
            "     28        \u001b[36m0.0955\u001b[0m       0.7898        0.5344  0.0892\n",
            "     29        \u001b[36m0.0895\u001b[0m       0.8068        0.5245  0.0871\n",
            "     30        \u001b[36m0.0838\u001b[0m       0.8011        0.5547  0.0878\n",
            "     31        \u001b[36m0.0785\u001b[0m       0.8011        0.5514  0.0883\n",
            "     32        \u001b[36m0.0738\u001b[0m       0.7955        0.5631  0.0933\n",
            "     33        \u001b[36m0.0697\u001b[0m       0.7898        0.5692  0.0925\n",
            "     34        \u001b[36m0.0661\u001b[0m       0.8068        0.5655  0.0909\n",
            "     35        \u001b[36m0.0625\u001b[0m       0.8068        0.5679  0.0891\n",
            "     36        \u001b[36m0.0594\u001b[0m       0.8011        0.6012  0.0876\n",
            "     37        \u001b[36m0.0552\u001b[0m       0.8182        0.5817  0.0877\n",
            "     38        \u001b[36m0.0543\u001b[0m       0.8125        0.5994  0.0887\n",
            "     39        \u001b[36m0.0509\u001b[0m       0.7841        0.6411  0.0887\n",
            "     40        \u001b[36m0.0507\u001b[0m       0.8125        0.6114  0.0893\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6547\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5699\u001b[0m  0.0696\n",
            "      2        \u001b[36m0.5649\u001b[0m       0.7557        \u001b[35m0.5516\u001b[0m  0.0719\n",
            "      3        \u001b[36m0.5624\u001b[0m       0.7557        \u001b[35m0.5511\u001b[0m  0.0782\n",
            "      4        \u001b[36m0.5600\u001b[0m       0.7557        0.5624  0.0722\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6607\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5750\u001b[0m  0.0708\n",
            "      2        \u001b[36m0.5621\u001b[0m       0.7500        \u001b[35m0.5490\u001b[0m  0.0717\n",
            "      3        0.5658       0.7500        0.5642  0.0710\n",
            "      4        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0707\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6688\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5700\u001b[0m  0.0694\n",
            "      2        \u001b[36m0.5624\u001b[0m       0.7500        \u001b[35m0.5595\u001b[0m  0.0739\n",
            "      3        \u001b[36m0.5605\u001b[0m       0.7500        0.5631  0.0779\n",
            "      4        \u001b[36m0.5510\u001b[0m       0.7500        0.5674  0.0753\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6316\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5604\u001b[0m  0.0694\n",
            "      2        \u001b[36m0.5588\u001b[0m       0.7500        0.5659  0.0788\n",
            "      3        0.5642       0.7500        0.5622  0.0783\n",
            "      4        0.5588       0.7500        0.5659  0.0735\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6781\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0697\n",
            "      2        \u001b[36m0.5723\u001b[0m       0.7500        \u001b[35m0.5707\u001b[0m  0.0869\n",
            "      3        \u001b[36m0.5660\u001b[0m       0.7500        0.5719  0.0757\n",
            "      4        \u001b[36m0.5608\u001b[0m       0.7500        \u001b[35m0.5635\u001b[0m  0.0712\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6817\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6006\u001b[0m  0.0696\n",
            "      2        \u001b[36m0.5762\u001b[0m       0.7500        \u001b[35m0.5672\u001b[0m  0.0709\n",
            "      3        \u001b[36m0.5710\u001b[0m       0.7500        \u001b[35m0.5634\u001b[0m  0.0709\n",
            "      4        \u001b[36m0.5645\u001b[0m       0.7500        0.5696  0.0770\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6545\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5761\u001b[0m  0.0740\n",
            "      2        \u001b[36m0.5760\u001b[0m       0.7500        \u001b[35m0.5672\u001b[0m  0.0705\n",
            "      3        \u001b[36m0.5626\u001b[0m       0.7500        \u001b[35m0.5645\u001b[0m  0.0708\n",
            "      4        \u001b[36m0.5584\u001b[0m       0.7500        0.5684  0.0727\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6764\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5844\u001b[0m  0.0698\n",
            "      2        \u001b[36m0.5731\u001b[0m       0.7500        \u001b[35m0.5593\u001b[0m  0.0715\n",
            "      3        \u001b[36m0.5628\u001b[0m       0.7500        0.5694  0.0751\n",
            "      4        \u001b[36m0.5590\u001b[0m       0.7500        \u001b[35m0.5576\u001b[0m  0.0718\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6805\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5606\u001b[0m  0.0694\n",
            "      2        \u001b[36m0.5948\u001b[0m       0.7500        \u001b[35m0.5585\u001b[0m  0.0708\n",
            "      3        \u001b[36m0.5667\u001b[0m       0.7500        0.5775  0.0707\n",
            "      4        \u001b[36m0.5594\u001b[0m       0.7500        0.5597  0.0713\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6825\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5741\u001b[0m  0.0693\n",
            "      2        \u001b[36m0.5894\u001b[0m       0.7500        \u001b[35m0.5666\u001b[0m  0.0802\n",
            "      3        \u001b[36m0.5636\u001b[0m       0.7500        0.5719  0.0754\n",
            "      4        \u001b[36m0.5609\u001b[0m       0.7500        \u001b[35m0.5640\u001b[0m  0.0795\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6555\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5600\u001b[0m  0.0721\n",
            "      2        \u001b[36m0.5788\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0732\n",
            "      3        \u001b[36m0.5593\u001b[0m       0.7557        0.5602  0.0707\n",
            "      4        \u001b[36m0.5559\u001b[0m       0.7557        0.5560  0.0710\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6364\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5626\u001b[0m  0.0748\n",
            "      2        \u001b[36m0.5644\u001b[0m       0.7500        0.5639  0.0724\n",
            "      3        \u001b[36m0.5581\u001b[0m       0.7500        \u001b[35m0.5626\u001b[0m  0.0695\n",
            "      4        \u001b[36m0.5554\u001b[0m       0.7500        \u001b[35m0.5625\u001b[0m  0.0706\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6385\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5730\u001b[0m  0.0689\n",
            "      2        \u001b[36m0.5598\u001b[0m       0.7500        \u001b[35m0.5667\u001b[0m  0.0712\n",
            "      3        0.5621       0.7500        \u001b[35m0.5625\u001b[0m  0.0752\n",
            "      4        \u001b[36m0.5552\u001b[0m       0.7500        0.5630  0.0784\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6082\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5674\u001b[0m  0.0751\n",
            "      2        \u001b[36m0.5650\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0711\n",
            "      3        \u001b[36m0.5575\u001b[0m       0.7500        0.5628  0.0707\n",
            "      4        \u001b[36m0.5532\u001b[0m       0.7500        0.5629  0.0708\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6731\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5788\u001b[0m  0.0686\n",
            "      2        \u001b[36m0.5672\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0749\n",
            "      3        \u001b[36m0.5650\u001b[0m       0.7500        0.5633  0.0709\n",
            "      4        \u001b[36m0.5595\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0707\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6444\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5681\u001b[0m  0.0698\n",
            "      2        \u001b[36m0.5742\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0730\n",
            "      3        \u001b[36m0.5628\u001b[0m       0.7500        0.5627  0.0707\n",
            "      4        \u001b[36m0.5614\u001b[0m       0.7500        0.5626  0.0702\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6444\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5785\u001b[0m  0.0754\n",
            "      2        \u001b[36m0.5981\u001b[0m       0.7500        \u001b[35m0.5632\u001b[0m  0.0715\n",
            "      3        \u001b[36m0.5593\u001b[0m       0.7500        0.5709  0.0729\n",
            "      4        0.5610       0.7500        \u001b[35m0.5627\u001b[0m  0.0801\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6899\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5804\u001b[0m  0.0720\n",
            "      2        \u001b[36m0.5750\u001b[0m       0.7500        \u001b[35m0.5640\u001b[0m  0.0713\n",
            "      3        \u001b[36m0.5624\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0798\n",
            "      4        \u001b[36m0.5561\u001b[0m       0.7500        0.5628  0.0752\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6847\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5812\u001b[0m  0.0694\n",
            "      2        \u001b[36m0.5768\u001b[0m       0.7500        \u001b[35m0.5632\u001b[0m  0.0709\n",
            "      3        \u001b[36m0.5657\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0709\n",
            "      4        \u001b[36m0.5588\u001b[0m       0.7500        0.5628  0.0712\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6719\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5631\u001b[0m  0.0697\n",
            "      2        \u001b[36m0.5942\u001b[0m       0.7500        0.5634  0.0771\n",
            "      3        \u001b[36m0.5607\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0888\n",
            "      4        \u001b[36m0.5566\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0705\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5897\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5669\u001b[0m  0.0622\n",
            "      2        \u001b[36m0.5775\u001b[0m       0.7557        \u001b[35m0.5597\u001b[0m  0.0654\n",
            "      3        \u001b[36m0.5597\u001b[0m       0.7557        \u001b[35m0.5575\u001b[0m  0.0636\n",
            "      4        \u001b[36m0.5591\u001b[0m       0.7557        0.5587  0.0678\n",
            "      5        \u001b[36m0.5575\u001b[0m       0.7557        \u001b[35m0.5564\u001b[0m  0.0683\n",
            "      6        \u001b[36m0.5558\u001b[0m       0.7557        \u001b[35m0.5561\u001b[0m  0.0633\n",
            "      7        0.5562       0.7557        0.5563  0.0633\n",
            "      8        0.5564       0.7557        \u001b[35m0.5560\u001b[0m  0.0638\n",
            "      9        0.5562       0.7557        0.5561  0.0631\n",
            "     10        0.5560       0.7557        0.5561  0.0672\n",
            "     11        0.5558       0.7557        0.5560  0.0634\n",
            "     12        \u001b[36m0.5557\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0666\n",
            "     13        \u001b[36m0.5556\u001b[0m       0.7557        0.5560  0.0634\n",
            "     14        \u001b[36m0.5556\u001b[0m       0.7557        0.5560  0.0638\n",
            "     15        \u001b[36m0.5555\u001b[0m       0.7557        0.5560  0.0635\n",
            "     16        \u001b[36m0.5554\u001b[0m       0.7557        0.5560  0.0643\n",
            "     17        \u001b[36m0.5553\u001b[0m       0.7557        0.5560  0.0660\n",
            "     18        \u001b[36m0.5552\u001b[0m       0.7557        0.5560  0.0643\n",
            "     19        \u001b[36m0.5550\u001b[0m       0.7557        0.5560  0.0657\n",
            "     20        \u001b[36m0.5549\u001b[0m       0.7557        0.5560  0.0661\n",
            "     21        \u001b[36m0.5547\u001b[0m       0.7557        0.5560  0.0630\n",
            "     22        \u001b[36m0.5545\u001b[0m       0.7557        0.5560  0.0629\n",
            "     23        \u001b[36m0.5542\u001b[0m       0.7557        0.5560  0.0666\n",
            "     24        \u001b[36m0.5540\u001b[0m       0.7557        0.5560  0.0640\n",
            "     25        \u001b[36m0.5538\u001b[0m       0.7557        0.5560  0.0632\n",
            "     26        \u001b[36m0.5536\u001b[0m       0.7557        0.5560  0.0641\n",
            "     27        \u001b[36m0.5532\u001b[0m       0.7557        0.5560  0.0667\n",
            "     28        \u001b[36m0.5525\u001b[0m       0.7557        0.5560  0.0660\n",
            "     29        \u001b[36m0.5519\u001b[0m       0.7557        0.5560  0.0689\n",
            "     30        0.6446       0.7557        0.5564  0.0651\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5773\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0629\n",
            "      2        \u001b[36m0.5721\u001b[0m       0.7500        \u001b[35m0.5632\u001b[0m  0.0644\n",
            "      3        \u001b[36m0.5589\u001b[0m       0.7500        0.5644  0.0635\n",
            "      4        \u001b[36m0.5585\u001b[0m       0.7500        \u001b[35m0.5628\u001b[0m  0.0641\n",
            "      5        \u001b[36m0.5557\u001b[0m       0.7500        \u001b[35m0.5628\u001b[0m  0.0635\n",
            "      6        0.5563       0.7500        0.5632  0.0645\n",
            "      7        0.5565       0.7500        \u001b[35m0.5624\u001b[0m  0.0675\n",
            "      8        0.5561       0.7500        \u001b[35m0.5623\u001b[0m  0.0657\n",
            "      9        0.5559       0.7500        \u001b[35m0.5623\u001b[0m  0.0646\n",
            "     10        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0643\n",
            "     11        0.5556       0.7500        0.5625  0.0657\n",
            "     12        0.5556       0.7500        0.5624  0.0664\n",
            "     13        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0676\n",
            "     14        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0642\n",
            "     15        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0644\n",
            "     16        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0651\n",
            "     17        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0635\n",
            "     18        \u001b[36m0.5548\u001b[0m       0.7500        0.5624  0.0633\n",
            "     19        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0647\n",
            "     20        \u001b[36m0.5544\u001b[0m       0.7500        0.5624  0.0686\n",
            "     21        \u001b[36m0.5542\u001b[0m       0.7500        0.5624  0.0652\n",
            "     22        \u001b[36m0.5541\u001b[0m       0.7500        0.5624  0.0646\n",
            "     23        \u001b[36m0.5539\u001b[0m       0.7500        0.5624  0.0644\n",
            "     24        \u001b[36m0.5538\u001b[0m       0.7500        0.5624  0.0637\n",
            "     25        \u001b[36m0.5536\u001b[0m       0.7500        0.5624  0.0637\n",
            "     26        \u001b[36m0.5534\u001b[0m       0.7500        0.5624  0.0651\n",
            "     27        \u001b[36m0.5530\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0695\n",
            "     28        \u001b[36m0.5525\u001b[0m       0.7500        \u001b[35m0.5619\u001b[0m  0.0657\n",
            "     29        \u001b[36m0.5519\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0649\n",
            "     30        0.7505       0.7500        0.5635  0.0649\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5808\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5723\u001b[0m  0.0623\n",
            "      2        \u001b[36m0.5720\u001b[0m       0.7500        \u001b[35m0.5662\u001b[0m  0.0642\n",
            "      3        \u001b[36m0.5585\u001b[0m       0.7500        \u001b[35m0.5630\u001b[0m  0.0665\n",
            "      4        \u001b[36m0.5579\u001b[0m       0.7500        0.5636  0.0635\n",
            "      5        \u001b[36m0.5562\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0634\n",
            "      6        \u001b[36m0.5551\u001b[0m       0.7500        0.5629  0.0631\n",
            "      7        0.5556       0.7500        0.5629  0.0644\n",
            "      8        0.5555       0.7500        0.5624  0.0633\n",
            "      9        0.5553       0.7500        \u001b[35m0.5623\u001b[0m  0.0637\n",
            "     10        0.5551       0.7500        0.5623  0.0661\n",
            "     11        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0633\n",
            "     12        \u001b[36m0.5548\u001b[0m       0.7500        0.5624  0.0676\n",
            "     13        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0638\n",
            "     14        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0664\n",
            "     15        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0648\n",
            "     16        \u001b[36m0.5543\u001b[0m       0.7500        0.5624  0.0645\n",
            "     17        \u001b[36m0.5541\u001b[0m       0.7500        0.5624  0.0640\n",
            "     18        \u001b[36m0.5540\u001b[0m       0.7500        0.5624  0.0635\n",
            "     19        \u001b[36m0.5538\u001b[0m       0.7500        0.5624  0.0629\n",
            "     20        \u001b[36m0.5537\u001b[0m       0.7500        0.5624  0.0632\n",
            "     21        \u001b[36m0.5536\u001b[0m       0.7500        0.5624  0.0655\n",
            "     22        \u001b[36m0.5534\u001b[0m       0.7500        0.5624  0.0636\n",
            "     23        \u001b[36m0.5533\u001b[0m       0.7500        0.5624  0.0654\n",
            "     24        \u001b[36m0.5530\u001b[0m       0.7500        0.5624  0.0660\n",
            "     25        \u001b[36m0.5525\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0655\n",
            "     26        \u001b[36m0.5520\u001b[0m       0.7500        \u001b[35m0.5616\u001b[0m  0.0628\n",
            "     27        \u001b[36m0.5514\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5588\u001b[0m  0.0668\n",
            "     28        0.7045       0.7500        0.5626  0.0651\n",
            "     29        0.5527       0.7500        0.5626  0.0647\n",
            "     30        0.5533       0.7500        0.5624  0.0676\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5995\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6017\u001b[0m  0.0640\n",
            "      2        \u001b[36m0.5829\u001b[0m       0.7500        \u001b[35m0.5645\u001b[0m  0.0631\n",
            "      3        \u001b[36m0.5604\u001b[0m       0.7500        0.5657  0.0638\n",
            "      4        \u001b[36m0.5604\u001b[0m       0.7500        \u001b[35m0.5640\u001b[0m  0.0631\n",
            "      5        \u001b[36m0.5555\u001b[0m       0.7500        \u001b[35m0.5625\u001b[0m  0.0631\n",
            "      6        \u001b[36m0.5549\u001b[0m       0.7500        0.5637  0.0629\n",
            "      7        0.5561       0.7500        0.5630  0.0631\n",
            "      8        0.5559       0.7500        \u001b[35m0.5624\u001b[0m  0.0684\n",
            "      9        0.5556       0.7500        \u001b[35m0.5623\u001b[0m  0.0632\n",
            "     10        0.5552       0.7500        0.5623  0.0629\n",
            "     11        0.5549       0.7500        0.5625  0.0632\n",
            "     12        0.5550       0.7500        0.5625  0.0643\n",
            "     13        0.5550       0.7500        0.5625  0.0715\n",
            "     14        0.5550       0.7500        0.5624  0.0653\n",
            "     15        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0686\n",
            "     16        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0652\n",
            "     17        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0631\n",
            "     18        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0645\n",
            "     19        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0633\n",
            "     20        \u001b[36m0.5544\u001b[0m       0.7500        0.5624  0.0645\n",
            "     21        \u001b[36m0.5543\u001b[0m       0.7500        0.5624  0.0647\n",
            "     22        \u001b[36m0.5541\u001b[0m       0.7500        0.5624  0.0693\n",
            "     23        \u001b[36m0.5540\u001b[0m       0.7500        0.5624  0.0640\n",
            "     24        \u001b[36m0.5539\u001b[0m       0.7500        0.5624  0.0648\n",
            "     25        \u001b[36m0.5537\u001b[0m       0.7500        0.5624  0.0635\n",
            "     26        \u001b[36m0.5536\u001b[0m       0.7500        0.5624  0.0637\n",
            "     27        \u001b[36m0.5534\u001b[0m       0.7500        0.5624  0.0637\n",
            "     28        \u001b[36m0.5532\u001b[0m       0.7500        0.5624  0.0681\n",
            "     29        \u001b[36m0.5531\u001b[0m       0.7500        0.5624  0.0660\n",
            "     30        \u001b[36m0.5530\u001b[0m       0.7500        0.5624  0.0641\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6074\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5673\u001b[0m  0.0619\n",
            "      2        \u001b[36m0.5770\u001b[0m       0.7500        0.5720  0.0643\n",
            "      3        \u001b[36m0.5621\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0638\n",
            "      4        \u001b[36m0.5573\u001b[0m       0.7500        0.5636  0.0636\n",
            "      5        0.5580       0.7500        0.5632  0.0663\n",
            "      6        \u001b[36m0.5568\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0646\n",
            "      7        \u001b[36m0.5561\u001b[0m       0.7500        0.5626  0.0639\n",
            "      8        0.5563       0.7500        0.5627  0.0632\n",
            "      9        0.5562       0.7500        0.5625  0.0647\n",
            "     10        \u001b[36m0.5561\u001b[0m       0.7500        0.5623  0.0647\n",
            "     11        \u001b[36m0.5560\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0646\n",
            "     12        \u001b[36m0.5559\u001b[0m       0.7500        0.5623  0.0705\n",
            "     13        \u001b[36m0.5558\u001b[0m       0.7500        0.5624  0.0733\n",
            "     14        \u001b[36m0.5558\u001b[0m       0.7500        0.5624  0.0646\n",
            "     15        \u001b[36m0.5557\u001b[0m       0.7500        0.5624  0.0634\n",
            "     16        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0642\n",
            "     17        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0629\n",
            "     18        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0660\n",
            "     19        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0643\n",
            "     20        \u001b[36m0.5553\u001b[0m       0.7500        0.5624  0.0645\n",
            "     21        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0644\n",
            "     22        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0644\n",
            "     23        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0660\n",
            "     24        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0633\n",
            "     25        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0659\n",
            "     26        \u001b[36m0.5544\u001b[0m       0.7500        0.5624  0.0650\n",
            "     27        \u001b[36m0.5542\u001b[0m       0.7500        0.5624  0.0651\n",
            "     28        \u001b[36m0.5539\u001b[0m       0.7500        0.5624  0.0657\n",
            "     29        \u001b[36m0.5536\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0670\n",
            "     30        \u001b[36m0.5532\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0673\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6274\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5713\u001b[0m  0.0623\n",
            "      2        \u001b[36m0.5918\u001b[0m       0.7500        \u001b[35m0.5689\u001b[0m  0.0662\n",
            "      3        \u001b[36m0.5609\u001b[0m       0.7500        \u001b[35m0.5632\u001b[0m  0.0645\n",
            "      4        0.5610       0.7500        0.5657  0.0632\n",
            "      5        0.5622       0.7500        0.5634  0.0630\n",
            "      6        \u001b[36m0.5605\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0633\n",
            "      7        \u001b[36m0.5601\u001b[0m       0.7500        0.5626  0.0690\n",
            "      8        \u001b[36m0.5600\u001b[0m       0.7500        0.5625  0.0651\n",
            "      9        \u001b[36m0.5595\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0635\n",
            "     10        \u001b[36m0.5595\u001b[0m       0.7500        0.5624  0.0641\n",
            "     11        0.5596       0.7500        0.5624  0.0650\n",
            "     12        0.5597       0.7500        0.5623  0.0678\n",
            "     13        0.5597       0.7500        \u001b[35m0.5623\u001b[0m  0.0645\n",
            "     14        0.5597       0.7500        0.5623  0.0659\n",
            "     15        0.5596       0.7500        0.5623  0.0718\n",
            "     16        0.5596       0.7500        0.5623  0.0642\n",
            "     17        0.5596       0.7500        0.5623  0.0642\n",
            "     18        0.5597       0.7500        0.5623  0.0671\n",
            "     19        0.5597       0.7500        0.5623  0.0651\n",
            "     20        0.5597       0.7500        0.5623  0.0633\n",
            "     21        0.5597       0.7500        0.5623  0.0635\n",
            "     22        0.5597       0.7500        0.5623  0.0630\n",
            "     23        0.5596       0.7500        0.5623  0.0636\n",
            "     24        0.5596       0.7500        0.5623  0.0642\n",
            "     25        0.5596       0.7500        0.5623  0.0657\n",
            "     26        0.5596       0.7500        0.5623  0.0652\n",
            "     27        0.5596       0.7500        0.5623  0.0633\n",
            "     28        0.5596       0.7500        0.5623  0.0649\n",
            "     29        0.5596       0.7500        0.5623  0.0632\n",
            "     30        0.5596       0.7500        0.5623  0.0639\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6485\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5662\u001b[0m  0.0622\n",
            "      2        \u001b[36m0.5822\u001b[0m       0.7500        0.5741  0.0701\n",
            "      3        \u001b[36m0.5605\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0631\n",
            "      4        \u001b[36m0.5556\u001b[0m       0.7500        0.5638  0.0640\n",
            "      5        0.5580       0.7500        0.5636  0.0666\n",
            "      6        0.5574       0.7500        0.5624  0.0644\n",
            "      7        0.5564       0.7500        0.5625  0.0632\n",
            "      8        0.5562       0.7500        0.5627  0.0638\n",
            "      9        0.5559       0.7500        0.5625  0.0662\n",
            "     10        0.5557       0.7500        \u001b[35m0.5623\u001b[0m  0.0661\n",
            "     11        0.5556       0.7500        \u001b[35m0.5623\u001b[0m  0.0651\n",
            "     12        0.5557       0.7500        \u001b[35m0.5623\u001b[0m  0.0643\n",
            "     13        0.5557       0.7500        0.5623  0.0676\n",
            "     14        0.5556       0.7500        0.5624  0.0636\n",
            "     15        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0663\n",
            "     16        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0644\n",
            "     17        \u001b[36m0.5554\u001b[0m       0.7500        0.5623  0.0636\n",
            "     18        \u001b[36m0.5553\u001b[0m       0.7500        0.5623  0.0644\n",
            "     19        \u001b[36m0.5553\u001b[0m       0.7500        0.5623  0.0630\n",
            "     20        \u001b[36m0.5552\u001b[0m       0.7500        0.5623  0.0630\n",
            "     21        \u001b[36m0.5552\u001b[0m       0.7500        0.5623  0.0634\n",
            "     22        \u001b[36m0.5551\u001b[0m       0.7500        0.5623  0.0658\n",
            "     23        \u001b[36m0.5550\u001b[0m       0.7500        0.5623  0.0660\n",
            "     24        \u001b[36m0.5550\u001b[0m       0.7500        0.5623  0.0648\n",
            "     25        \u001b[36m0.5549\u001b[0m       0.7500        0.5623  0.0644\n",
            "     26        \u001b[36m0.5548\u001b[0m       0.7500        0.5623  0.0634\n",
            "     27        \u001b[36m0.5547\u001b[0m       0.7500        0.5623  0.0656\n",
            "     28        \u001b[36m0.5546\u001b[0m       0.7500        0.5623  0.0661\n",
            "     29        \u001b[36m0.5546\u001b[0m       0.7500        0.5623  0.0636\n",
            "     30        \u001b[36m0.5545\u001b[0m       0.7500        0.5623  0.0634\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6008\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5647\u001b[0m  0.0620\n",
            "      2        \u001b[36m0.5705\u001b[0m       0.7500        0.5685  0.0634\n",
            "      3        \u001b[36m0.5589\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0642\n",
            "      4        \u001b[36m0.5560\u001b[0m       0.7500        0.5631  0.0657\n",
            "      5        0.5572       0.7500        0.5628  0.0675\n",
            "      6        0.5568       0.7500        \u001b[35m0.5623\u001b[0m  0.0647\n",
            "      7        0.5563       0.7500        0.5625  0.0636\n",
            "      8        0.5562       0.7500        0.5626  0.0632\n",
            "      9        \u001b[36m0.5559\u001b[0m       0.7500        0.5624  0.0633\n",
            "     10        \u001b[36m0.5557\u001b[0m       0.7500        0.5623  0.0670\n",
            "     11        \u001b[36m0.5557\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0671\n",
            "     12        0.5557       0.7500        0.5623  0.0652\n",
            "     13        \u001b[36m0.5557\u001b[0m       0.7500        0.5624  0.0684\n",
            "     14        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0654\n",
            "     15        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0630\n",
            "     16        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0669\n",
            "     17        \u001b[36m0.5553\u001b[0m       0.7500        0.5624  0.0633\n",
            "     18        \u001b[36m0.5553\u001b[0m       0.7500        0.5624  0.0627\n",
            "     19        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0637\n",
            "     20        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0634\n",
            "     21        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0632\n",
            "     22        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0632\n",
            "     23        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0658\n",
            "     24        \u001b[36m0.5548\u001b[0m       0.7500        0.5624  0.0653\n",
            "     25        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0638\n",
            "     26        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0643\n",
            "     27        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0640\n",
            "     28        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0672\n",
            "     29        \u001b[36m0.5544\u001b[0m       0.7500        0.5624  0.0629\n",
            "     30        \u001b[36m0.5543\u001b[0m       0.7500        0.5624  0.0662\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6005\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5629\u001b[0m  0.0633\n",
            "      2        \u001b[36m0.5713\u001b[0m       0.7500        0.5679  0.0636\n",
            "      3        \u001b[36m0.5614\u001b[0m       0.7500        \u001b[35m0.5625\u001b[0m  0.0633\n",
            "      4        \u001b[36m0.5570\u001b[0m       0.7500        0.5628  0.0630\n",
            "      5        0.5574       0.7500        0.5629  0.0642\n",
            "      6        \u001b[36m0.5570\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0637\n",
            "      7        \u001b[36m0.5566\u001b[0m       0.7500        0.5624  0.0670\n",
            "      8        0.5567       0.7500        0.5625  0.0633\n",
            "      9        \u001b[36m0.5566\u001b[0m       0.7500        0.5624  0.0635\n",
            "     10        \u001b[36m0.5564\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0635\n",
            "     11        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0640\n",
            "     12        \u001b[36m0.5563\u001b[0m       0.7500        0.5623  0.0641\n",
            "     13        \u001b[36m0.5562\u001b[0m       0.7500        0.5623  0.0693\n",
            "     14        \u001b[36m0.5562\u001b[0m       0.7500        0.5624  0.0638\n",
            "     15        \u001b[36m0.5561\u001b[0m       0.7500        0.5624  0.0658\n",
            "     16        \u001b[36m0.5561\u001b[0m       0.7500        0.5624  0.0657\n",
            "     17        \u001b[36m0.5560\u001b[0m       0.7500        0.5624  0.0645\n",
            "     18        \u001b[36m0.5559\u001b[0m       0.7500        0.5623  0.0635\n",
            "     19        \u001b[36m0.5558\u001b[0m       0.7500        0.5623  0.0642\n",
            "     20        \u001b[36m0.5558\u001b[0m       0.7500        0.5624  0.0673\n",
            "     21        \u001b[36m0.5557\u001b[0m       0.7500        0.5624  0.0632\n",
            "     22        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0634\n",
            "     23        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0636\n",
            "     24        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0635\n",
            "     25        \u001b[36m0.5553\u001b[0m       0.7500        0.5624  0.0653\n",
            "     26        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0667\n",
            "     27        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0693\n",
            "     28        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0667\n",
            "     29        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0633\n",
            "     30        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0631\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6012\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5654\u001b[0m  0.0622\n",
            "      2        \u001b[36m0.5844\u001b[0m       0.7500        0.5748  0.0635\n",
            "      3        \u001b[36m0.5672\u001b[0m       0.7500        \u001b[35m0.5637\u001b[0m  0.0633\n",
            "      4        \u001b[36m0.5577\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0647\n",
            "      5        \u001b[36m0.5566\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0652\n",
            "      6        \u001b[36m0.5564\u001b[0m       0.7500        0.5627  0.0633\n",
            "      7        0.5570       0.7500        0.5637  0.0645\n",
            "      8        0.5579       0.7500        0.5640  0.0633\n",
            "      9        0.5578       0.7500        0.5636  0.0635\n",
            "     10        0.5572       0.7500        0.5632  0.0633\n",
            "     11        0.5567       0.7500        0.5630  0.0670\n",
            "     12        0.5565       0.7500        0.5630  0.0644\n",
            "     13        0.5565       0.7500        0.5631  0.0707\n",
            "     14        0.5566       0.7500        0.5632  0.0661\n",
            "     15        0.5566       0.7500        0.5633  0.0632\n",
            "     16        0.5565       0.7500        0.5633  0.0634\n",
            "     17        \u001b[36m0.5563\u001b[0m       0.7500        0.5632  0.0635\n",
            "     18        \u001b[36m0.5562\u001b[0m       0.7500        0.5632  0.0658\n",
            "     19        \u001b[36m0.5561\u001b[0m       0.7500        0.5632  0.0644\n",
            "     20        \u001b[36m0.5560\u001b[0m       0.7500        0.5632  0.0640\n",
            "     21        \u001b[36m0.5559\u001b[0m       0.7500        0.5632  0.0642\n",
            "     22        \u001b[36m0.5559\u001b[0m       0.7500        0.5632  0.0634\n",
            "     23        \u001b[36m0.5558\u001b[0m       0.7500        0.5632  0.0631\n",
            "     24        \u001b[36m0.5557\u001b[0m       0.7500        0.5632  0.0630\n",
            "     25        \u001b[36m0.5556\u001b[0m       0.7500        0.5632  0.0665\n",
            "     26        \u001b[36m0.5555\u001b[0m       0.7500        0.5632  0.0681\n",
            "     27        \u001b[36m0.5554\u001b[0m       0.7500        0.5632  0.0673\n",
            "     28        \u001b[36m0.5553\u001b[0m       0.7500        0.5632  0.0679\n",
            "     29        \u001b[36m0.5552\u001b[0m       0.7500        0.5632  0.0667\n",
            "     30        \u001b[36m0.5551\u001b[0m       0.7500        0.5632  0.0656\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5993\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5789\u001b[0m  0.0650\n",
            "      2        \u001b[36m0.5832\u001b[0m       0.7557        \u001b[35m0.5555\u001b[0m  0.0688\n",
            "      3        \u001b[36m0.5607\u001b[0m       0.7557        0.5647  0.0684\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.5837\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5755\u001b[0m  0.0654\n",
            "      2        \u001b[36m0.5684\u001b[0m       0.7500        \u001b[35m0.5667\u001b[0m  0.0684\n",
            "      3        \u001b[36m0.5603\u001b[0m       0.7500        0.5720  0.0661\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6020\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6068\u001b[0m  0.0653\n",
            "      2        \u001b[36m0.5863\u001b[0m       0.7500        \u001b[35m0.5658\u001b[0m  0.0665\n",
            "      3        \u001b[36m0.5629\u001b[0m       0.7500        \u001b[35m0.5589\u001b[0m  0.0688\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6030\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6071\u001b[0m  0.0657\n",
            "      2        \u001b[36m0.5786\u001b[0m       0.7500        \u001b[35m0.5592\u001b[0m  0.0658\n",
            "      3        \u001b[36m0.5650\u001b[0m       0.7500        0.5758  0.0733\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6103\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5744\u001b[0m  0.0653\n",
            "      2        \u001b[36m0.5814\u001b[0m       0.7500        0.5746  0.0664\n",
            "      3        \u001b[36m0.5587\u001b[0m       0.7500        \u001b[35m0.5658\u001b[0m  0.0718\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6069\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5729\u001b[0m  0.0651\n",
            "      2        \u001b[36m0.5748\u001b[0m       0.7500        \u001b[35m0.5662\u001b[0m  0.0665\n",
            "      3        \u001b[36m0.5639\u001b[0m       0.7500        \u001b[35m0.5650\u001b[0m  0.0663\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6114\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5788\u001b[0m  0.0651\n",
            "      2        \u001b[36m0.5687\u001b[0m       0.7500        \u001b[35m0.5737\u001b[0m  0.0663\n",
            "      3        \u001b[36m0.5602\u001b[0m       0.7500        \u001b[35m0.5654\u001b[0m  0.0690\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6213\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5679\u001b[0m  0.0658\n",
            "      2        \u001b[36m0.5678\u001b[0m       0.7500        0.5763  0.0729\n",
            "      3        \u001b[36m0.5585\u001b[0m       0.7500        \u001b[35m0.5631\u001b[0m  0.0662\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6178\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5749\u001b[0m  0.0649\n",
            "      2        \u001b[36m0.5782\u001b[0m       0.7500        \u001b[35m0.5640\u001b[0m  0.0697\n",
            "      3        \u001b[36m0.5636\u001b[0m       0.7500        0.5660  0.0675\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6297\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5753\u001b[0m  0.0652\n",
            "      2        \u001b[36m0.6035\u001b[0m       0.7500        0.5801  0.0675\n",
            "      3        \u001b[36m0.5709\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0676\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7663\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5726\u001b[0m  0.0556\n",
            "      2        \u001b[36m0.5714\u001b[0m       0.7557        \u001b[35m0.5535\u001b[0m  0.0598\n",
            "      3        \u001b[36m0.5539\u001b[0m       0.7557        0.5566  0.0582\n",
            "      4        0.5568       0.7557        0.5619  0.0587\n",
            "      5        0.5588       0.7557        0.5637  0.0586\n",
            "      6        0.5564       0.7557        0.5718  0.0571\n",
            "      7        0.5540       0.7557        0.5581  0.0568\n",
            "      8        \u001b[36m0.5519\u001b[0m       0.7557        0.5577  0.0575\n",
            "      9        0.5549       0.7557        0.5583  0.0576\n",
            "     10        0.5564       0.7557        0.5572  0.0646\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6467\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5671\u001b[0m  0.0573\n",
            "      2        \u001b[36m0.5611\u001b[0m       0.7500        0.5677  0.0647\n",
            "      3        \u001b[36m0.5576\u001b[0m       0.7500        \u001b[35m0.5630\u001b[0m  0.0574\n",
            "      4        \u001b[36m0.5570\u001b[0m       0.7500        0.5673  0.0569\n",
            "      5        \u001b[36m0.5551\u001b[0m       0.7500        \u001b[35m0.5595\u001b[0m  0.0570\n",
            "      6        \u001b[36m0.5538\u001b[0m       0.7500        0.5665  0.0564\n",
            "      7        0.5551       0.7500        0.5678  0.0569\n",
            "      8        0.5556       0.7500        0.5651  0.0604\n",
            "      9        0.5565       0.7500        \u001b[35m0.5582\u001b[0m  0.0567\n",
            "     10        0.5559       0.7500        0.5629  0.0573\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7424\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5740\u001b[0m  0.0570\n",
            "      2        \u001b[36m0.5683\u001b[0m       0.7500        \u001b[35m0.5719\u001b[0m  0.0571\n",
            "      3        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5694\u001b[0m  0.0570\n",
            "      4        0.5573       0.7500        \u001b[35m0.5600\u001b[0m  0.0566\n",
            "      5        0.5600       0.7500        0.5615  0.0599\n",
            "      6        \u001b[36m0.5550\u001b[0m       0.7500        0.5673  0.0580\n",
            "      7        0.5565       0.7500        0.5655  0.0578\n",
            "      8        0.5555       0.7500        0.5605  0.0575\n",
            "      9        0.5575       0.7500        0.5708  0.0607\n",
            "     10        \u001b[36m0.5540\u001b[0m       0.7500        0.5660  0.0605\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7332\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5747\u001b[0m  0.0577\n",
            "      2        \u001b[36m0.5641\u001b[0m       0.7500        \u001b[35m0.5649\u001b[0m  0.0570\n",
            "      3        \u001b[36m0.5552\u001b[0m       0.7500        0.5731  0.0570\n",
            "      4        0.5552       0.7500        0.5694  0.0567\n",
            "      5        0.5563       0.7500        0.5686  0.0570\n",
            "      6        \u001b[36m0.5538\u001b[0m       0.7500        \u001b[35m0.5646\u001b[0m  0.0568\n",
            "      7        0.5546       0.7500        \u001b[35m0.5566\u001b[0m  0.0627\n",
            "      8        \u001b[36m0.5503\u001b[0m       0.7500        \u001b[35m0.5565\u001b[0m  0.0591\n",
            "      9        0.5577       0.7500        0.5675  0.0570\n",
            "     10        0.5578       0.7500        \u001b[35m0.5561\u001b[0m  0.0570\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7738\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5660\u001b[0m  0.0613\n",
            "      2        \u001b[36m0.5676\u001b[0m       0.7500        0.5709  0.0553\n",
            "      3        \u001b[36m0.5663\u001b[0m       0.7500        \u001b[35m0.5595\u001b[0m  0.0610\n",
            "      4        \u001b[36m0.5563\u001b[0m       0.7500        0.5611  0.0637\n",
            "      5        0.5601       0.7500        0.5641  0.0605\n",
            "      6        0.5575       0.7500        0.5664  0.0571\n",
            "      7        0.5565       0.7500        0.5641  0.0564\n",
            "      8        \u001b[36m0.5548\u001b[0m       0.7500        0.5602  0.0577\n",
            "      9        0.5578       0.7500        0.5698  0.0598\n",
            "     10        0.5552       0.7500        0.5639  0.0617\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8115\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5785\u001b[0m  0.0592\n",
            "      2        \u001b[36m0.5770\u001b[0m       0.7500        \u001b[35m0.5649\u001b[0m  0.0570\n",
            "      3        \u001b[36m0.5664\u001b[0m       0.7500        \u001b[35m0.5638\u001b[0m  0.0578\n",
            "      4        \u001b[36m0.5628\u001b[0m       0.7500        \u001b[35m0.5590\u001b[0m  0.0598\n",
            "      5        0.5640       0.7500        0.5702  0.0576\n",
            "      6        \u001b[36m0.5596\u001b[0m       0.7500        0.5665  0.0574\n",
            "      7        0.5633       0.7500        0.5638  0.0570\n",
            "      8        0.5645       0.7500        0.5704  0.0574\n",
            "      9        0.5650       0.7500        0.5652  0.0581\n",
            "     10        0.5608       0.7500        0.5633  0.0576\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7094\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5658\u001b[0m  0.0562\n",
            "      2        \u001b[36m0.5610\u001b[0m       0.7500        0.5685  0.0608\n",
            "      3        \u001b[36m0.5598\u001b[0m       0.7500        \u001b[35m0.5595\u001b[0m  0.0576\n",
            "      4        0.5606       0.7500        0.5634  0.0614\n",
            "      5        \u001b[36m0.5558\u001b[0m       0.7500        0.5730  0.0584\n",
            "      6        \u001b[36m0.5557\u001b[0m       0.7500        0.5619  0.0569\n",
            "      7        0.5559       0.7500        0.5622  0.0571\n",
            "      8        \u001b[36m0.5538\u001b[0m       0.7500        0.5612  0.0596\n",
            "      9        \u001b[36m0.5533\u001b[0m       0.7500        0.5623  0.0597\n",
            "     10        0.5554       0.7500        0.5602  0.0576\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8163\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5667\u001b[0m  0.0559\n",
            "      2        \u001b[36m0.5714\u001b[0m       0.7500        0.5806  0.0567\n",
            "      3        \u001b[36m0.5705\u001b[0m       0.7500        \u001b[35m0.5564\u001b[0m  0.0572\n",
            "      4        \u001b[36m0.5608\u001b[0m       0.7500        0.5671  0.0624\n",
            "      5        \u001b[36m0.5600\u001b[0m       0.7500        0.5673  0.0601\n",
            "      6        \u001b[36m0.5590\u001b[0m       0.7500        0.5617  0.0583\n",
            "      7        \u001b[36m0.5569\u001b[0m       0.7500        0.5590  0.0595\n",
            "      8        \u001b[36m0.5552\u001b[0m       0.7500        0.5658  0.0610\n",
            "      9        \u001b[36m0.5518\u001b[0m       0.7500        0.5659  0.0570\n",
            "     10        0.5548       0.7500        0.5689  0.0578\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7672\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5617\u001b[0m  0.0561\n",
            "      2        \u001b[36m0.5655\u001b[0m       0.7500        0.5749  0.0578\n",
            "      3        0.5684       0.7500        0.5676  0.0571\n",
            "      4        \u001b[36m0.5610\u001b[0m       0.7500        0.5711  0.0566\n",
            "      5        0.5618       0.7500        \u001b[35m0.5614\u001b[0m  0.0585\n",
            "      6        \u001b[36m0.5551\u001b[0m       0.7500        0.5626  0.0568\n",
            "      7        0.5571       0.7500        0.5633  0.0571\n",
            "      8        0.5565       0.7500        0.5683  0.0603\n",
            "      9        0.5596       0.7500        0.5659  0.0573\n",
            "     10        0.5590       0.7500        0.5647  0.0571\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.7434\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5617\u001b[0m  0.0559\n",
            "      2        \u001b[36m0.5607\u001b[0m       0.7500        0.5760  0.0577\n",
            "      3        \u001b[36m0.5593\u001b[0m       0.7500        \u001b[35m0.5553\u001b[0m  0.0593\n",
            "      4        0.5622       0.7500        0.5725  0.0607\n",
            "      5        0.5628       0.7500        0.5564  0.0663\n",
            "      6        0.5632       0.7500        0.5620  0.0567\n",
            "      7        \u001b[36m0.5557\u001b[0m       0.7500        0.5619  0.0575\n",
            "      8        0.5574       0.7500        0.5672  0.0574\n",
            "      9        0.5579       0.7500        0.5668  0.0588\n",
            "     10        0.5596       0.7500        0.5697  0.0616\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6484\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5579\u001b[0m  0.0707\n",
            "      2        \u001b[36m0.5595\u001b[0m       0.7557        0.5633  0.0717\n",
            "      3        0.5621       0.7557        \u001b[35m0.5571\u001b[0m  0.0744\n",
            "      4        \u001b[36m0.5566\u001b[0m       0.7557        \u001b[35m0.5564\u001b[0m  0.0716\n",
            "      5        \u001b[36m0.5562\u001b[0m       0.7557        0.5570  0.0723\n",
            "      6        \u001b[36m0.5557\u001b[0m       0.7557        \u001b[35m0.5563\u001b[0m  0.0733\n",
            "      7        \u001b[36m0.5548\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0833\n",
            "      8        \u001b[36m0.5548\u001b[0m       0.7557        0.5561  0.0727\n",
            "      9        0.5549       0.7557        0.5560  0.0763\n",
            "     10        0.5548       0.7557        \u001b[35m0.5560\u001b[0m  0.0720\n",
            "     11        \u001b[36m0.5547\u001b[0m       0.7557        0.5560  0.0721\n",
            "     12        \u001b[36m0.5546\u001b[0m       0.7557        0.5560  0.0718\n",
            "     13        \u001b[36m0.5544\u001b[0m       0.7557        0.5560  0.0743\n",
            "     14        \u001b[36m0.5543\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0736\n",
            "     15        \u001b[36m0.5543\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0722\n",
            "     16        \u001b[36m0.5543\u001b[0m       0.7557        \u001b[35m0.5560\u001b[0m  0.0724\n",
            "     17        \u001b[36m0.5540\u001b[0m       0.7557        0.5560  0.0717\n",
            "     18        \u001b[36m0.5539\u001b[0m       0.7557        \u001b[35m0.5554\u001b[0m  0.0712\n",
            "     19        \u001b[36m0.5536\u001b[0m       0.7557        \u001b[35m0.5551\u001b[0m  0.0722\n",
            "     20        \u001b[36m0.5529\u001b[0m       0.7557        \u001b[35m0.5545\u001b[0m  0.0749\n",
            "     21        \u001b[36m0.5520\u001b[0m       0.7557        \u001b[35m0.5534\u001b[0m  0.0763\n",
            "     22        \u001b[36m0.5503\u001b[0m       0.7557        \u001b[35m0.5517\u001b[0m  0.0721\n",
            "     23        \u001b[36m0.5475\u001b[0m       0.7557        \u001b[35m0.5488\u001b[0m  0.0766\n",
            "     24        \u001b[36m0.5431\u001b[0m       0.7557        \u001b[35m0.5439\u001b[0m  0.0720\n",
            "     25        \u001b[36m0.5348\u001b[0m       0.7557        \u001b[35m0.5337\u001b[0m  0.0763\n",
            "     26        \u001b[36m0.5173\u001b[0m       0.7557        \u001b[35m0.5169\u001b[0m  0.0713\n",
            "     27        \u001b[36m0.4951\u001b[0m       0.7557        0.5361  0.0715\n",
            "     28        \u001b[36m0.4787\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.5060\u001b[0m  0.0716\n",
            "     29        \u001b[36m0.4378\u001b[0m       0.7102        \u001b[35m0.5010\u001b[0m  0.0721\n",
            "     30        \u001b[36m0.4181\u001b[0m       0.7045        0.5163  0.0709\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6882\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5915\u001b[0m  0.0715\n",
            "      2        \u001b[36m0.5630\u001b[0m       0.7500        \u001b[35m0.5680\u001b[0m  0.0766\n",
            "      3        0.5655       0.7500        0.5703  0.0727\n",
            "      4        \u001b[36m0.5601\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0731\n",
            "      5        \u001b[36m0.5563\u001b[0m       0.7500        0.5627  0.0714\n",
            "      6        0.5564       0.7500        0.5628  0.0765\n",
            "      7        \u001b[36m0.5556\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0721\n",
            "      8        \u001b[36m0.5548\u001b[0m       0.7500        0.5625  0.0718\n",
            "      9        0.5548       0.7500        0.5627  0.0738\n",
            "     10        0.5549       0.7500        0.5626  0.0771\n",
            "     11        0.5548       0.7500        0.5624  0.0720\n",
            "     12        \u001b[36m0.5546\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0716\n",
            "     13        \u001b[36m0.5545\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0718\n",
            "     14        \u001b[36m0.5544\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0715\n",
            "     15        \u001b[36m0.5543\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0722\n",
            "     16        \u001b[36m0.5542\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0743\n",
            "     17        \u001b[36m0.5541\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0721\n",
            "     18        \u001b[36m0.5539\u001b[0m       0.7500        \u001b[35m0.5620\u001b[0m  0.0722\n",
            "     19        \u001b[36m0.5537\u001b[0m       0.7500        \u001b[35m0.5618\u001b[0m  0.0712\n",
            "     20        \u001b[36m0.5531\u001b[0m       0.7500        \u001b[35m0.5614\u001b[0m  0.0766\n",
            "     21        \u001b[36m0.5514\u001b[0m       0.7500        \u001b[35m0.5605\u001b[0m  0.0722\n",
            "     22        \u001b[36m0.5484\u001b[0m       0.7500        \u001b[35m0.5597\u001b[0m  0.0721\n",
            "     23        \u001b[36m0.5439\u001b[0m       0.7500        \u001b[35m0.5579\u001b[0m  0.0739\n",
            "     24        \u001b[36m0.5358\u001b[0m       0.7500        \u001b[35m0.5554\u001b[0m  0.0742\n",
            "     25        \u001b[36m0.5202\u001b[0m       0.7500        \u001b[35m0.5543\u001b[0m  0.0723\n",
            "     26        \u001b[36m0.5006\u001b[0m       0.7443        0.5750  0.0722\n",
            "     27        \u001b[36m0.4969\u001b[0m       0.6875        0.5912  0.0730\n",
            "     28        \u001b[36m0.4681\u001b[0m       0.7273        0.5808  0.0724\n",
            "     29        \u001b[36m0.4568\u001b[0m       0.7330        0.5661  0.0792\n",
            "     30        \u001b[36m0.4371\u001b[0m       0.6818        0.6198  0.0817\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6237\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5646\u001b[0m  0.0762\n",
            "      2        \u001b[36m0.5586\u001b[0m       0.7500        0.5687  0.0722\n",
            "      3        0.5619       0.7500        \u001b[35m0.5639\u001b[0m  0.0782\n",
            "      4        \u001b[36m0.5574\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0746\n",
            "      5        \u001b[36m0.5568\u001b[0m       0.7500        0.5627  0.0784\n",
            "      6        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0718\n",
            "      7        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0738\n",
            "      8        \u001b[36m0.5555\u001b[0m       0.7500        0.5626  0.0722\n",
            "      9        0.5556       0.7500        0.5625  0.0733\n",
            "     10        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0722\n",
            "     11        \u001b[36m0.5554\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0718\n",
            "     12        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0742\n",
            "     13        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0725\n",
            "     14        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0720\n",
            "     15        \u001b[36m0.5549\u001b[0m       0.7500        0.5624  0.0769\n",
            "     16        \u001b[36m0.5548\u001b[0m       0.7500        0.5624  0.0783\n",
            "     17        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0764\n",
            "     18        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0716\n",
            "     19        \u001b[36m0.5544\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0744\n",
            "     20        \u001b[36m0.5542\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0729\n",
            "     21        \u001b[36m0.5540\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0717\n",
            "     22        \u001b[36m0.5538\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0734\n",
            "     23        \u001b[36m0.5535\u001b[0m       0.7500        \u001b[35m0.5620\u001b[0m  0.0730\n",
            "     24        \u001b[36m0.5534\u001b[0m       0.7500        \u001b[35m0.5605\u001b[0m  0.0724\n",
            "     25        \u001b[36m0.5524\u001b[0m       0.7500        \u001b[35m0.5601\u001b[0m  0.0766\n",
            "     26        \u001b[36m0.5508\u001b[0m       0.7500        \u001b[35m0.5591\u001b[0m  0.0726\n",
            "     27        \u001b[36m0.5483\u001b[0m       0.7500        \u001b[35m0.5557\u001b[0m  0.0770\n",
            "     28        \u001b[36m0.5472\u001b[0m       0.7500        \u001b[35m0.5518\u001b[0m  0.0716\n",
            "     29        \u001b[36m0.5399\u001b[0m       0.7500        \u001b[35m0.5394\u001b[0m  0.0767\n",
            "     30        \u001b[36m0.5334\u001b[0m       0.6477        0.5918  0.0727\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6256\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5624\u001b[0m  0.0725\n",
            "      2        \u001b[36m0.5570\u001b[0m       0.7500        0.5727  0.0723\n",
            "      3        0.5616       0.7500        0.5628  0.0717\n",
            "      4        0.5570       0.7500        0.5630  0.0816\n",
            "      5        \u001b[36m0.5563\u001b[0m       0.7500        0.5626  0.0763\n",
            "      6        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0716\n",
            "      7        \u001b[36m0.5543\u001b[0m       0.7500        0.5629  0.0743\n",
            "      8        0.5548       0.7500        0.5627  0.0728\n",
            "      9        0.5548       0.7500        0.5624  0.0735\n",
            "     10        0.5546       0.7500        \u001b[35m0.5623\u001b[0m  0.0739\n",
            "     11        \u001b[36m0.5543\u001b[0m       0.7500        0.5624  0.0722\n",
            "     12        \u001b[36m0.5541\u001b[0m       0.7500        0.5624  0.0765\n",
            "     13        \u001b[36m0.5540\u001b[0m       0.7500        0.5624  0.0777\n",
            "     14        \u001b[36m0.5540\u001b[0m       0.7500        0.5624  0.0720\n",
            "     15        \u001b[36m0.5539\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0717\n",
            "     16        \u001b[36m0.5537\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0718\n",
            "     17        \u001b[36m0.5535\u001b[0m       0.7500        \u001b[35m0.5616\u001b[0m  0.0733\n",
            "     18        \u001b[36m0.5529\u001b[0m       0.7500        \u001b[35m0.5612\u001b[0m  0.0737\n",
            "     19        \u001b[36m0.5519\u001b[0m       0.7500        \u001b[35m0.5604\u001b[0m  0.0755\n",
            "     20        \u001b[36m0.5504\u001b[0m       0.7500        \u001b[35m0.5589\u001b[0m  0.0718\n",
            "     21        \u001b[36m0.5472\u001b[0m       0.7500        \u001b[35m0.5561\u001b[0m  0.0732\n",
            "     22        \u001b[36m0.5416\u001b[0m       0.7500        \u001b[35m0.5510\u001b[0m  0.0733\n",
            "     23        \u001b[36m0.5322\u001b[0m       0.7500        \u001b[35m0.5407\u001b[0m  0.0716\n",
            "     24        \u001b[36m0.5093\u001b[0m       0.7500        \u001b[35m0.5248\u001b[0m  0.0712\n",
            "     25        \u001b[36m0.4600\u001b[0m       0.7330        0.5280  0.0752\n",
            "     26        0.4722       \u001b[32m0.7784\u001b[0m        \u001b[35m0.5082\u001b[0m  0.0812\n",
            "     27        0.4838       0.7727        0.5231  0.0746\n",
            "     28        0.4713       0.7557        \u001b[35m0.5053\u001b[0m  0.0718\n",
            "     29        \u001b[36m0.4286\u001b[0m       0.7614        \u001b[35m0.4813\u001b[0m  0.0722\n",
            "     30        \u001b[36m0.4068\u001b[0m       0.7330        0.4973  0.0715\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6235\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5739\u001b[0m  0.0699\n",
            "      2        \u001b[36m0.5624\u001b[0m       0.7500        \u001b[35m0.5629\u001b[0m  0.0746\n",
            "      3        \u001b[36m0.5595\u001b[0m       0.7500        0.5654  0.0718\n",
            "      4        \u001b[36m0.5590\u001b[0m       0.7500        0.5636  0.0815\n",
            "      5        \u001b[36m0.5570\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0828\n",
            "      6        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0722\n",
            "      7        \u001b[36m0.5563\u001b[0m       0.7500        0.5624  0.0736\n",
            "      8        \u001b[36m0.5562\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0716\n",
            "      9        \u001b[36m0.5559\u001b[0m       0.7500        0.5623  0.0776\n",
            "     10        \u001b[36m0.5558\u001b[0m       0.7500        0.5624  0.0717\n",
            "     11        \u001b[36m0.5557\u001b[0m       0.7500        0.5624  0.0717\n",
            "     12        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0716\n",
            "     13        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0731\n",
            "     14        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0826\n",
            "     15        \u001b[36m0.5553\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0716\n",
            "     16        \u001b[36m0.5552\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0716\n",
            "     17        \u001b[36m0.5550\u001b[0m       0.7500        0.5623  0.0729\n",
            "     18        \u001b[36m0.5549\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0749\n",
            "     19        \u001b[36m0.5547\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0750\n",
            "     20        \u001b[36m0.5545\u001b[0m       0.7500        \u001b[35m0.5609\u001b[0m  0.0716\n",
            "     21        \u001b[36m0.5540\u001b[0m       0.7500        \u001b[35m0.5604\u001b[0m  0.0717\n",
            "     22        \u001b[36m0.5532\u001b[0m       0.7500        \u001b[35m0.5600\u001b[0m  0.0760\n",
            "     23        \u001b[36m0.5518\u001b[0m       0.7500        \u001b[35m0.5594\u001b[0m  0.0715\n",
            "     24        \u001b[36m0.5500\u001b[0m       0.7500        \u001b[35m0.5585\u001b[0m  0.0756\n",
            "     25        \u001b[36m0.5475\u001b[0m       0.7500        \u001b[35m0.5569\u001b[0m  0.0738\n",
            "     26        \u001b[36m0.5440\u001b[0m       0.7500        \u001b[35m0.5545\u001b[0m  0.0725\n",
            "     27        \u001b[36m0.5385\u001b[0m       0.7500        \u001b[35m0.5508\u001b[0m  0.0723\n",
            "     28        \u001b[36m0.5285\u001b[0m       0.7500        \u001b[35m0.5399\u001b[0m  0.0720\n",
            "     29        \u001b[36m0.5169\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5313\u001b[0m  0.0718\n",
            "     30        \u001b[36m0.4889\u001b[0m       \u001b[32m0.7614\u001b[0m        \u001b[35m0.5250\u001b[0m  0.0737\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6828\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5912\u001b[0m  0.0712\n",
            "      2        \u001b[36m0.5735\u001b[0m       0.7500        \u001b[35m0.5638\u001b[0m  0.0733\n",
            "      3        \u001b[36m0.5685\u001b[0m       0.7500        0.5669  0.0727\n",
            "      4        \u001b[36m0.5624\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0733\n",
            "      5        \u001b[36m0.5589\u001b[0m       0.7500        \u001b[35m0.5626\u001b[0m  0.0749\n",
            "      6        0.5595       0.7500        0.5630  0.0759\n",
            "      7        0.5598       0.7500        \u001b[35m0.5626\u001b[0m  0.0712\n",
            "      8        0.5595       0.7500        \u001b[35m0.5623\u001b[0m  0.0716\n",
            "      9        0.5593       0.7500        0.5624  0.0753\n",
            "     10        0.5593       0.7500        0.5624  0.0738\n",
            "     11        0.5592       0.7500        \u001b[35m0.5623\u001b[0m  0.0719\n",
            "     12        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0740\n",
            "     13        0.5591       0.7500        0.5623  0.0728\n",
            "     14        0.5591       0.7500        0.5623  0.0718\n",
            "     15        0.5591       0.7500        0.5623  0.0727\n",
            "     16        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0771\n",
            "     17        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0711\n",
            "     18        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0753\n",
            "     19        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0807\n",
            "     20        0.5591       0.7500        0.5623  0.0742\n",
            "     21        0.5591       0.7500        0.5623  0.0755\n",
            "     22        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0712\n",
            "     23        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0713\n",
            "     24        0.5591       0.7500        \u001b[35m0.5623\u001b[0m  0.0736\n",
            "     25        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0729\n",
            "     26        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0741\n",
            "     27        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0717\n",
            "     28        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0722\n",
            "     29        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0713\n",
            "     30        0.5590       0.7500        \u001b[35m0.5623\u001b[0m  0.0765\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6450\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5653\u001b[0m  0.0702\n",
            "      2        \u001b[36m0.5658\u001b[0m       0.7500        0.5683  0.0754\n",
            "      3        \u001b[36m0.5623\u001b[0m       0.7500        \u001b[35m0.5642\u001b[0m  0.0721\n",
            "      4        \u001b[36m0.5560\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0730\n",
            "      5        \u001b[36m0.5559\u001b[0m       0.7500        0.5629  0.0703\n",
            "      6        0.5566       0.7500        0.5626  0.0752\n",
            "      7        0.5562       0.7500        \u001b[35m0.5623\u001b[0m  0.0713\n",
            "      8        \u001b[36m0.5559\u001b[0m       0.7500        0.5624  0.0712\n",
            "      9        \u001b[36m0.5557\u001b[0m       0.7500        0.5625  0.0819\n",
            "     10        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0731\n",
            "     11        \u001b[36m0.5553\u001b[0m       0.7500        0.5623  0.0738\n",
            "     12        \u001b[36m0.5553\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0797\n",
            "     13        \u001b[36m0.5552\u001b[0m       0.7500        0.5623  0.0718\n",
            "     14        \u001b[36m0.5552\u001b[0m       0.7500        0.5623  0.0720\n",
            "     15        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0750\n",
            "     16        \u001b[36m0.5550\u001b[0m       0.7500        0.5624  0.0725\n",
            "     17        \u001b[36m0.5549\u001b[0m       0.7500        0.5623  0.0719\n",
            "     18        \u001b[36m0.5548\u001b[0m       0.7500        0.5623  0.0743\n",
            "     19        \u001b[36m0.5547\u001b[0m       0.7500        0.5623  0.0770\n",
            "     20        \u001b[36m0.5546\u001b[0m       0.7500        0.5623  0.0781\n",
            "     21        \u001b[36m0.5545\u001b[0m       0.7500        0.5623  0.0728\n",
            "     22        \u001b[36m0.5544\u001b[0m       0.7500        0.5623  0.0814\n",
            "     23        \u001b[36m0.5543\u001b[0m       0.7500        0.5623  0.0728\n",
            "     24        \u001b[36m0.5541\u001b[0m       0.7500        0.5623  0.0758\n",
            "     25        \u001b[36m0.5540\u001b[0m       0.7500        0.5623  0.0727\n",
            "     26        \u001b[36m0.5539\u001b[0m       0.7500        0.5623  0.0774\n",
            "     27        \u001b[36m0.5538\u001b[0m       0.7500        0.5623  0.0725\n",
            "     28        \u001b[36m0.5537\u001b[0m       0.7500        0.5623  0.0799\n",
            "     29        \u001b[36m0.5537\u001b[0m       0.7500        0.5623  0.0742\n",
            "     30        \u001b[36m0.5536\u001b[0m       0.7500        0.5623  0.0753\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6250\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5704\u001b[0m  0.0778\n",
            "      2        \u001b[36m0.5634\u001b[0m       0.7500        \u001b[35m0.5643\u001b[0m  0.0756\n",
            "      3        \u001b[36m0.5611\u001b[0m       0.7500        0.5658  0.0728\n",
            "      4        \u001b[36m0.5580\u001b[0m       0.7500        \u001b[35m0.5631\u001b[0m  0.0722\n",
            "      5        \u001b[36m0.5558\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0738\n",
            "      6        0.5558       0.7500        0.5624  0.0754\n",
            "      7        0.5560       0.7500        0.5624  0.0727\n",
            "      8        0.5559       0.7500        \u001b[35m0.5623\u001b[0m  0.0729\n",
            "      9        \u001b[36m0.5557\u001b[0m       0.7500        0.5624  0.0728\n",
            "     10        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0729\n",
            "     11        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0725\n",
            "     12        \u001b[36m0.5553\u001b[0m       0.7500        0.5624  0.0812\n",
            "     13        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0783\n",
            "     14        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0721\n",
            "     15        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0726\n",
            "     16        \u001b[36m0.5550\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0740\n",
            "     17        \u001b[36m0.5549\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0720\n",
            "     18        \u001b[36m0.5547\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0761\n",
            "     19        \u001b[36m0.5546\u001b[0m       0.7500        \u001b[35m0.5621\u001b[0m  0.0731\n",
            "     20        \u001b[36m0.5544\u001b[0m       0.7500        \u001b[35m0.5619\u001b[0m  0.0746\n",
            "     21        \u001b[36m0.5542\u001b[0m       0.7500        \u001b[35m0.5616\u001b[0m  0.0725\n",
            "     22        \u001b[36m0.5539\u001b[0m       0.7500        \u001b[35m0.5614\u001b[0m  0.0724\n",
            "     23        \u001b[36m0.5535\u001b[0m       0.7500        \u001b[35m0.5610\u001b[0m  0.0728\n",
            "     24        \u001b[36m0.5529\u001b[0m       0.7500        \u001b[35m0.5607\u001b[0m  0.0753\n",
            "     25        \u001b[36m0.5519\u001b[0m       0.7500        \u001b[35m0.5600\u001b[0m  0.0790\n",
            "     26        \u001b[36m0.5500\u001b[0m       0.7500        \u001b[35m0.5583\u001b[0m  0.0729\n",
            "     27        \u001b[36m0.5460\u001b[0m       0.7500        \u001b[35m0.5545\u001b[0m  0.0754\n",
            "     28        \u001b[36m0.5368\u001b[0m       0.7500        \u001b[35m0.5433\u001b[0m  0.0732\n",
            "     29        \u001b[36m0.5210\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5296\u001b[0m  0.0744\n",
            "     30        \u001b[36m0.4929\u001b[0m       0.7557        \u001b[35m0.5174\u001b[0m  0.0760\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6220\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5693\u001b[0m  0.0714\n",
            "      2        \u001b[36m0.5627\u001b[0m       0.7500        \u001b[35m0.5645\u001b[0m  0.0734\n",
            "      3        \u001b[36m0.5620\u001b[0m       0.7500        0.5651  0.0736\n",
            "      4        \u001b[36m0.5584\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0781\n",
            "      5        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0740\n",
            "      6        \u001b[36m0.5561\u001b[0m       0.7500        0.5625  0.0774\n",
            "      7        \u001b[36m0.5560\u001b[0m       0.7500        0.5624  0.0748\n",
            "      8        \u001b[36m0.5557\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0784\n",
            "      9        \u001b[36m0.5556\u001b[0m       0.7500        0.5624  0.0726\n",
            "     10        \u001b[36m0.5555\u001b[0m       0.7500        0.5624  0.0730\n",
            "     11        \u001b[36m0.5554\u001b[0m       0.7500        0.5624  0.0727\n",
            "     12        \u001b[36m0.5552\u001b[0m       0.7500        0.5624  0.0774\n",
            "     13        \u001b[36m0.5551\u001b[0m       0.7500        0.5624  0.0746\n",
            "     14        \u001b[36m0.5550\u001b[0m       0.7500        0.5623  0.0723\n",
            "     15        \u001b[36m0.5548\u001b[0m       0.7500        0.5624  0.0725\n",
            "     16        \u001b[36m0.5547\u001b[0m       0.7500        0.5624  0.0736\n",
            "     17        \u001b[36m0.5546\u001b[0m       0.7500        0.5624  0.0723\n",
            "     18        \u001b[36m0.5545\u001b[0m       0.7500        0.5624  0.0791\n",
            "     19        \u001b[36m0.5543\u001b[0m       0.7500        0.5624  0.0720\n",
            "     20        \u001b[36m0.5541\u001b[0m       0.7500        \u001b[35m0.5623\u001b[0m  0.0728\n",
            "     21        \u001b[36m0.5538\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0769\n",
            "     22        \u001b[36m0.5536\u001b[0m       0.7500        \u001b[35m0.5620\u001b[0m  0.0733\n",
            "     23        \u001b[36m0.5532\u001b[0m       0.7500        0.5620  0.0777\n",
            "     24        \u001b[36m0.5529\u001b[0m       0.7500        \u001b[35m0.5618\u001b[0m  0.0792\n",
            "     25        \u001b[36m0.5529\u001b[0m       0.7500        \u001b[35m0.5618\u001b[0m  0.0736\n",
            "     26        \u001b[36m0.5524\u001b[0m       0.7500        0.5622  0.0744\n",
            "     27        \u001b[36m0.5522\u001b[0m       0.7500        0.5623  0.0731\n",
            "     28        \u001b[36m0.5520\u001b[0m       0.7500        0.5622  0.0736\n",
            "     29        \u001b[36m0.5518\u001b[0m       0.7500        0.5621  0.0737\n",
            "     30        \u001b[36m0.5517\u001b[0m       0.7500        0.5619  0.0834\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6513\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5769\u001b[0m  0.0775\n",
            "      2        \u001b[36m0.5637\u001b[0m       0.7500        \u001b[35m0.5664\u001b[0m  0.0831\n",
            "      3        0.5686       0.7500        0.5709  0.0730\n",
            "      4        0.5642       0.7500        \u001b[35m0.5654\u001b[0m  0.0780\n",
            "      5        \u001b[36m0.5582\u001b[0m       0.7500        \u001b[35m0.5628\u001b[0m  0.0726\n",
            "      6        \u001b[36m0.5563\u001b[0m       0.7500        \u001b[35m0.5624\u001b[0m  0.0760\n",
            "      7        \u001b[36m0.5558\u001b[0m       0.7500        0.5625  0.0759\n",
            "      8        0.5559       0.7500        0.5629  0.0725\n",
            "      9        0.5562       0.7500        0.5634  0.0720\n",
            "     10        0.5565       0.7500        0.5636  0.0733\n",
            "     11        0.5565       0.7500        0.5636  0.0721\n",
            "     12        0.5563       0.7500        0.5634  0.0784\n",
            "     13        0.5560       0.7500        0.5632  0.0738\n",
            "     14        \u001b[36m0.5558\u001b[0m       0.7500        0.5632  0.0727\n",
            "     15        \u001b[36m0.5556\u001b[0m       0.7500        0.5632  0.0722\n",
            "     16        \u001b[36m0.5555\u001b[0m       0.7500        0.5632  0.0725\n",
            "     17        \u001b[36m0.5555\u001b[0m       0.7500        0.5633  0.0778\n",
            "     18        \u001b[36m0.5554\u001b[0m       0.7500        0.5633  0.0764\n",
            "     19        \u001b[36m0.5552\u001b[0m       0.7500        0.5633  0.0771\n",
            "     20        \u001b[36m0.5551\u001b[0m       0.7500        0.5633  0.0724\n",
            "     21        \u001b[36m0.5549\u001b[0m       0.7500        0.5632  0.0720\n",
            "     22        \u001b[36m0.5547\u001b[0m       0.7500        0.5633  0.0731\n",
            "     23        \u001b[36m0.5546\u001b[0m       0.7500        0.5633  0.0755\n",
            "     24        \u001b[36m0.5544\u001b[0m       0.7500        0.5633  0.0730\n",
            "     25        \u001b[36m0.5542\u001b[0m       0.7500        0.5633  0.0738\n",
            "     26        \u001b[36m0.5539\u001b[0m       0.7500        0.5632  0.0781\n",
            "     27        \u001b[36m0.5536\u001b[0m       0.7500        0.5631  0.0727\n",
            "     28        \u001b[36m0.5534\u001b[0m       0.7500        0.5630  0.0734\n",
            "     29        \u001b[36m0.5532\u001b[0m       0.7500        0.5629  0.0756\n",
            "     30        \u001b[36m0.5529\u001b[0m       0.7500        \u001b[35m0.5613\u001b[0m  0.0754\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.8451\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6329\u001b[0m  0.0978\n",
            "      2        \u001b[36m0.7812\u001b[0m       0.7500        \u001b[35m0.5671\u001b[0m  0.0982\n",
            "      3        \u001b[36m0.5971\u001b[0m       0.7143        0.5852  0.0995\n",
            "      4        \u001b[36m0.5388\u001b[0m       0.7194        0.5818  0.0998\n",
            "      5        \u001b[36m0.4537\u001b[0m       0.7245        \u001b[35m0.5367\u001b[0m  0.1043\n",
            "      6        \u001b[36m0.3625\u001b[0m       0.7449        0.5424  0.0989\n",
            "      7        \u001b[36m0.2838\u001b[0m       \u001b[32m0.7551\u001b[0m        \u001b[35m0.5363\u001b[0m  0.1004\n",
            "      8        \u001b[36m0.2167\u001b[0m       \u001b[32m0.7806\u001b[0m        \u001b[35m0.5165\u001b[0m  0.0989\n",
            "      9        \u001b[36m0.1981\u001b[0m       0.7551        0.5282  0.0987\n",
            "     10        \u001b[36m0.1750\u001b[0m       0.6224        0.8531  0.0997\n",
            "     11        0.2028       \u001b[32m0.7857\u001b[0m        0.6223  0.1033\n",
            "     12        0.2265       0.7806        0.5226  0.1000\n",
            "     13        0.1869       0.6837        0.8361  0.0989\n",
            "     14        0.1841       \u001b[32m0.8010\u001b[0m        0.5808  0.1000\n",
            "     15        0.1824       0.7806        0.5440  0.0983\n",
            "     16        \u001b[36m0.1324\u001b[0m       \u001b[32m0.8061\u001b[0m        0.5575  0.0981\n",
            "     17        \u001b[36m0.0874\u001b[0m       0.7857        0.6110  0.1007\n",
            "     18        \u001b[36m0.0640\u001b[0m       0.7908        0.6399  0.1024\n",
            "     19        \u001b[36m0.0508\u001b[0m       \u001b[32m0.8163\u001b[0m        0.6588  0.0996\n",
            "     20        \u001b[36m0.0410\u001b[0m       0.8112        0.7023  0.0990\n",
            "     21        \u001b[36m0.0347\u001b[0m       0.8061        0.7269  0.0981\n",
            "     22        \u001b[36m0.0312\u001b[0m       0.8010        0.7591  0.1027\n",
            "     23        \u001b[36m0.0286\u001b[0m       0.8010        0.7832  0.0985\n",
            "     24        \u001b[36m0.0269\u001b[0m       0.8061        0.8067  0.0980\n",
            "     25        \u001b[36m0.0252\u001b[0m       0.8061        0.8296  0.0979\n",
            "     26        \u001b[36m0.0243\u001b[0m       0.8010        0.8429  0.0991\n",
            "     27        \u001b[36m0.0235\u001b[0m       0.8010        0.8581  0.1002\n",
            "     28        \u001b[36m0.0226\u001b[0m       0.8010        0.8709  0.1020\n",
            "     29        \u001b[36m0.0219\u001b[0m       0.7959        0.8832  0.1006\n",
            "     30        \u001b[36m0.0214\u001b[0m       0.7959        0.8940  0.1015\n",
            "     31        \u001b[36m0.0210\u001b[0m       0.7959        0.9032  0.0991\n",
            "     32        \u001b[36m0.0206\u001b[0m       0.7959        0.9126  0.0988\n",
            "     33        \u001b[36m0.0204\u001b[0m       0.7959        0.9173  0.0996\n",
            "     34        \u001b[36m0.0201\u001b[0m       0.7959        0.9240  0.1022\n",
            "     35        \u001b[36m0.0199\u001b[0m       0.7959        0.9314  0.1020\n",
            "     36        \u001b[36m0.0197\u001b[0m       0.7959        0.9366  0.1020\n",
            "     37        \u001b[36m0.0195\u001b[0m       0.7959        0.9465  0.1003\n",
            "     38        \u001b[36m0.0194\u001b[0m       0.7959        0.9523  0.0998\n",
            "     39        \u001b[36m0.0193\u001b[0m       0.7959        0.9609  0.0991\n",
            "     40        \u001b[36m0.0192\u001b[0m       0.7959        0.9642  0.1004\n",
            "CPU times: user 2min 7s, sys: 12.4 s, total: 2min 19s\n",
            "Wall time: 2min 20s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=<class '__main__.RequirementRNN'>,\n",
              "),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'lr': [0.1, 0.01, 0.001],\n",
              "                                        'max_epochs': [3, 4, 5, 10, 30, 40],\n",
              "                                        'module__dropout': [0, 0.1, 0.3],\n",
              "                                        'module__embedding_dim': [64, 128, 256],\n",
              "                                        'module__num_layers': [1, 2],\n",
              "                                        'module__num_units': [64, 128, 256],\n",
              "                                        'module__rec_layer_type': ['gru',\n",
              "                                                                   'lstm']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-du77whJlv",
        "outputId": "aa8fd218-a661-4fb8-f41f-44001da70bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "search.best_score_, search.best_params_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7800757416368609,\n",
              " {'lr': 0.01,\n",
              "  'max_epochs': 40,\n",
              "  'module__dropout': 0,\n",
              "  'module__embedding_dim': 256,\n",
              "  'module__num_layers': 1,\n",
              "  'module__num_units': 256,\n",
              "  'module__rec_layer_type': 'gru'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-YysVNK0XaK"
      },
      "source": [
        "search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSOuK4sTdYMg"
      },
      "source": [
        "lista_taggeada = list(df['Tagged_Req'].str.split(','))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPtK2f6aSBTW"
      },
      "source": [
        "df['Tagged_Req'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC9Nrptev92q"
      },
      "source": [
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKd2QhuQxUU1"
      },
      "source": [
        "# Display Learning curves to see if overfitting or underfitting data\n",
        "\n",
        "\n",
        "\n",
        "*   By observing the learning curves, I can tell if the Neural Network overfitted or underfitted the data.\n",
        "* Overfit : if the training loss curve is significantly lower than the validation loss curve.\n",
        "* Underfit: if both the training loss curve and the validation loss curve are very high loss.\n",
        "* Ideal: both the training loss and validation loss curves have a minimal gap between them and converge to a very low loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iunxb-u0xhKA"
      },
      "source": [
        "# get training and validation loss\n",
        "epochs = [i for i in range(len(search.best_estimator_.history))]\n",
        "train_loss = search.best_estimator_.history[:,'train_loss']\n",
        "valid_loss = search.best_estimator_.history[:,'valid_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Czf1zhCxoMD"
      },
      "source": [
        "plt.plot(epochs,train_loss,'g-');\n",
        "plt.plot(epochs,valid_loss,'r-');\n",
        "plt.title('Training Loss Curves');\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Mean Squared Error');\n",
        "plt.legend(['Train','Validation']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skg5KBzsxrfw"
      },
      "source": [
        "# See Regression Metrics to evaluate on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7LE5M1Vxs4U"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFgD59Vpx6UM"
      },
      "source": [
        "# predict on test data\n",
        "y_pred = search.best_estimator_.predict(X_transformado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYpJU8dUvH2"
      },
      "source": [
        "search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feefPG0IyDfl"
      },
      "source": [
        "MSE(y,y_pred)**(1/2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KL_vWC7qyfZ"
      },
      "source": [
        "np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GiEjP7WquiY"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN391CiTyFrx"
      },
      "source": [
        "sns.kdeplot(y.squeeze(), label='true', shade= True, color = 'blue', linestyle = \"dotted\")\n",
        "plt.xlabel('Singularity');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7X-10MUYFWR"
      },
      "source": [
        "sns.kdeplot(y_pred.squeeze(), label='estimate', shade=True, color= 'orange')\n",
        "plt.xlabel('Singularity');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_32U4M5ZyIUx"
      },
      "source": [
        "plt.xlim(-0.15, 0.15)\n",
        "sns.distplot(y.squeeze()-y_pred.squeeze(),label='error');\n",
        "plt.xlabel('Singularidad Error') ;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaMfpfeAMyQ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6V26-eXkASh"
      },
      "source": [
        "# Codigo para Transformar Requerimientos a Tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBt84Jwjkls2"
      },
      "source": [
        "Se importan las librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThgJQwrq6n1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rfBZlGlkfv0"
      },
      "source": [
        "Insertar los requerimientos a continuacion en modo de Lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdrqJ9FWkaQr"
      },
      "source": [
        "lista_de_req = ['The ATM shall display the Customer Account_Number, Account_ Balance, and so on.','The system shall allow the client to consult third-party accounts added to transfer.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqkaZaMWko2t"
      },
      "source": [
        "Se obtienen los tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQsSl9d-1_DO"
      },
      "source": [
        "list_word_tokenized = [word_tokenize(str(x)) for x in lista_de_req]\n",
        "print(list_word_tokenized)\n",
        "pos_tagged = [nltk.pos_tag(x) for x in list_word_tokenized]\n",
        "print(pos_tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAydxV8ruRHt"
      },
      "source": [
        "lista_taggeada = []\n",
        "for oracion in pos_tagged:\n",
        "  oracion_tagged = [] \n",
        "  for palabra in oracion:\n",
        "    oracion_tagged.append(palabra[1])\n",
        "  lista_taggeada.append(oracion_tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMmOYGkluD4d"
      },
      "source": [
        "separator = ','\n",
        "flat_list = [separator.join(l) for l in lista_taggeada]\n",
        "print(flat_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1744_0DXwDqv"
      },
      "source": [
        "- CC coordinating conjunction\n",
        "- CD cardinal digit\n",
        "- DT determiner\n",
        "- EX existential there (like: “there is” … think of it like “there exists”)\n",
        "- FW foreign word\n",
        "- IN preposition/subordinating conjunction\n",
        "- JJ adjective ‘big’\n",
        "- JJR adjective, comparative ‘bigger’\n",
        "- JJS adjective, superlative ‘biggest’\n",
        "- LS list marker 1)\n",
        "- MD modal could, will\n",
        "- NN noun, singular ‘desk’\n",
        "- NNS noun plural ‘desks’\n",
        "- NNP proper noun, singular ‘Harrison’\n",
        "- NNPS proper noun, plural ‘Americans’\n",
        "- PDT predeterminer ‘all the kids’\n",
        "- POS possessive ending parent’s\n",
        "- PRP personal pronoun I, he, she\n",
        "- PRP possessive pronoun my, his, hers\n",
        "- RB adverb very, silently,\n",
        "- RBR adverb, comparative better\n",
        "- RBS adverb, superlative best\n",
        "- RP particle give up\n",
        "- TO, to go ‘to’ the store.\n",
        "- UH interjection, errrrrrrrm\n",
        "- VB verb, base form take\n",
        "- VBD verb, past tense took\n",
        "- VBG verb, gerund/present participle taking\n",
        "- VBN verb, past participle taken\n",
        "- VBP verb, sing. present, non-3d take\n",
        "- VBZ verb, 3rd person sing. present takes\n",
        "- WDT wh-determiner which\n",
        "- WP wh-pronoun who, what\n",
        "- WP possessive wh-pronoun whose\n",
        "- WRB wh-abverb where, when"
      ]
    }
  ]
}